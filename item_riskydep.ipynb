{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7e8f33d-2648-44f2-aa69-77d02e0e5637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bdc29e6-2471-476c-a777-31a60eb00e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>liveStrict</th>\n",
       "      <th>hukou</th>\n",
       "      <th>homeNum</th>\n",
       "      <th>chaiqian</th>\n",
       "      <th>home_mianji</th>\n",
       "      <th>zhaiwu</th>\n",
       "      <th>family_income</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>...</th>\n",
       "      <th>Stress1</th>\n",
       "      <th>Stress2</th>\n",
       "      <th>Stress3</th>\n",
       "      <th>Emontion_regulate1</th>\n",
       "      <th>Emontion_regulate2</th>\n",
       "      <th>Emontion_regulate3</th>\n",
       "      <th>Emontion_regulate4</th>\n",
       "      <th>Emontion_regulate5</th>\n",
       "      <th>Emontion_regulate6</th>\n",
       "      <th>risk_depression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number  liveStrict  hukou  homeNum  chaiqian  home_mianji  zhaiwu  \\\n",
       "0       1           1      1        2         0            4       1   \n",
       "1       2           1      1        1         0            3       0   \n",
       "2       3           1      1        3         1            4       1   \n",
       "3       4           2      2        1         0            4       0   \n",
       "4       5           1      1        0         0            1       0   \n",
       "\n",
       "   family_income  gender  age  ...  Stress1  Stress2  Stress3  \\\n",
       "0              8       2    2  ...        2        2        3   \n",
       "1              1       2    2  ...        2        5        3   \n",
       "2              2       2    5  ...        2        2        2   \n",
       "3              3       2    1  ...        1        1        1   \n",
       "4              1       1    2  ...        5        4        4   \n",
       "\n",
       "   Emontion_regulate1  Emontion_regulate2  Emontion_regulate3  \\\n",
       "0                   1                   1                   3   \n",
       "1                   3                   3                   3   \n",
       "2                   1                   2                   2   \n",
       "3                   0                   1                   4   \n",
       "4                   4                   3                   2   \n",
       "\n",
       "   Emontion_regulate4  Emontion_regulate5  Emontion_regulate6  risk_depression  \n",
       "0                   0                   3                   3                0  \n",
       "1                   3                   3                   1                0  \n",
       "2                   0                   0                   3                0  \n",
       "3                   3                   3                   3                1  \n",
       "4                   3                   3                   3                1  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(r'C:\\Users\\Lenovo\\Desktop\\ML_health\\pbicr_11\\Item_Scores_dep.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26604d6c-1040-4b89-bee1-018522aae35d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11031, 97)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('risk_depression', axis = 1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1eac3b0-cdff-4eca-a799-ec6f97c485a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11031,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df['risk_depression']\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97eb4c63-90dc-47d0-bbde-74e90bd82a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "risk_depression\n",
       "0    8832\n",
       "1    2199\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aadc5e15-6bd9-431f-835b-0bf74fba9118",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f3d3c82-d876-4018-9391-a3a044df1087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Number                int64\n",
       "liveStrict            int64\n",
       "hukou                 int64\n",
       "homeNum               int64\n",
       "chaiqian              int64\n",
       "                      ...  \n",
       "Emontion_regulate2    int64\n",
       "Emontion_regulate3    int64\n",
       "Emontion_regulate4    int64\n",
       "Emontion_regulate5    int64\n",
       "Emontion_regulate6    int64\n",
       "Length: 97, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d07a888-fdc7-40ab-9772-5b8aaf57b295",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47220b54-34d0-44f9-8d9c-e758a91524b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Number                int64\n",
       "liveStrict            int64\n",
       "hukou                 int64\n",
       "homeNum               int64\n",
       "chaiqian              int64\n",
       "                      ...  \n",
       "Emontion_regulate2    int64\n",
       "Emontion_regulate3    int64\n",
       "Emontion_regulate4    int64\n",
       "Emontion_regulate5    int64\n",
       "Emontion_regulate6    int64\n",
       "Length: 97, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af4b6324-ab5b-4a15-90c2-597b71051856",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5055455f-34fe-4f47-b59f-25015346d9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5afcc04b-eed3-4d59-b387-07984fc2dc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "risk_depression\n",
      "0    7963\n",
      "1    1964\n",
      "Name: count, dtype: int64\n",
      "risk_depression\n",
      "0    7963\n",
      "1    7963\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts())  # 原始训练集的类别分布\n",
    "print(y_train_resampled.value_counts())  # 过采样后的类别分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "282d8893-60cb-42c9-a661-98cbb5864c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.concat([y_train_resampled, X_train_resampled], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8eb33ef6-361d-4ca1-809f-f77755a5fc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_excel(r'C:\\Users\\Lenovo\\Desktop\\ML_health\\pbicr_11\\Item_Scores_dep_smote.xlsx',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc634740-1821-49c1-b0e3-0cc7079a4476",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_excel(r'C:\\Users\\Lenovo\\Desktop\\ML_health\\pbicr_11\\Item_Scores_dep_smote.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "231de8c1-7351-414d-b559-a638d3c71778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15926, 97)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df3.drop('risk_depression', axis = 1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac7724bc-4770-4032-a0dd-17aa9977ecae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15926,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df3['risk_depression']\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2db78dc-4ca1-4ccd-9f71-b2c2a57d6486",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df3.drop(['risk_depression', 'Number'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e1614b8-460c-415d-abc2-852cf6e7fed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15926, 96)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3931c17d-8590-4002-a7da-d8dd12d18341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15926,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df3['risk_depression']\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb54e83d-ae15-4ed1-9a4e-ba462d2cf54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2b626d8-7f59-4300-83d2-d1ca4cd42d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.8257863315493241\n",
      "Average Precision: 0.8261158179569087\n",
      "Average Recall: 0.825942973296077\n",
      "Average F1 Score: 0.8256544389953294\n",
      "Average ROC AUC: 0.825942973296077\n",
      "Average Specificity: 0.8111400566172963\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# 创建决策树分类器\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# 创建 KFold 交叉验证分割器\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# 初始化指标列表\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "roc_auc_scores = []\n",
    "specificity_scores = []\n",
    "\n",
    "# 进行10×10交叉验证\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    # 分割数据，使用 .iloc 来根据行索引选择数据\n",
    "    X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    \n",
    "    # 训练模型\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # 进行预测\n",
    "    y_pred_fold = model.predict(X_test_fold)\n",
    "    \n",
    "    # 计算并存储每个指标\n",
    "    accuracy = accuracy_score(y_test_fold, y_pred_fold)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    \n",
    "    precision = precision_score(y_test_fold, y_pred_fold, average='macro')\n",
    "    precision_scores.append(precision)\n",
    "    \n",
    "    recall = recall_score(y_test_fold, y_pred_fold, average='macro')\n",
    "    recall_scores.append(recall)\n",
    "    \n",
    "    f1 = f1_score(y_test_fold, y_pred_fold, average='macro')\n",
    "    f1_scores.append(f1)\n",
    "    \n",
    "    # 如果模型是二分类模型，并且你已经有了模型预测的概率，可以计算ROC AUC\n",
    "    if len(set(y_test_fold)) == 2:\n",
    "        y_scores_fold = model.predict_proba(X_test_fold)[:, 1]  # 获取正类的概率\n",
    "        roc_auc = roc_auc_score(y_test_fold, y_scores_fold)\n",
    "        roc_auc_scores.append(roc_auc)\n",
    "    \n",
    "    # 计算Specificity\n",
    "    conf_mat_fold = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "    tn, fp, fn, tp = conf_mat_fold.ravel()\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    specificity_scores.append(specificity)\n",
    "\n",
    "# 输出每个指标的平均值\n",
    "print(\"Average Accuracy:\", sum(accuracy_scores) / len(accuracy_scores))\n",
    "print(\"Average Precision:\", sum(precision_scores) / len(precision_scores))\n",
    "print(\"Average Recall:\", sum(recall_scores) / len(recall_scores))\n",
    "print(\"Average F1 Score:\", sum(f1_scores) / len(f1_scores))\n",
    "if roc_auc_scores:\n",
    "    print(\"Average ROC AUC:\", sum(roc_auc_scores) / len(roc_auc_scores))\n",
    "print(\"Average Specificity:\", sum(specificity_scores) / len(specificity_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e847b28-64f1-4e92-8908-f8eb3297c347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.800251980367138\n",
      "Average Precision: 0.8002320300772651\n",
      "Average Recall: 0.8000825929057764\n",
      "Average F1 Score: 0.8000325328466514\n",
      "Average ROC AUC: 0.8753800901859886\n",
      "Average Specificity: 0.7894916282550632\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "\n",
    "model = GaussianNB()\n",
    "\n",
    "# 创建 KFold 交叉验证分割器\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# 初始化指标列表\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "roc_auc_scores = []\n",
    "specificity_scores = []\n",
    "\n",
    "# 进行10×10交叉验证\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    # 分割数据，使用 .iloc 来根据行索引选择数据\n",
    "    X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    \n",
    "    # 训练模型\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # 进行预测\n",
    "    y_pred_fold = model.predict(X_test_fold)\n",
    "    \n",
    "    # 计算并存储每个指标\n",
    "    accuracy = accuracy_score(y_test_fold, y_pred_fold)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    \n",
    "    precision = precision_score(y_test_fold, y_pred_fold, average='macro')\n",
    "    precision_scores.append(precision)\n",
    "    \n",
    "    recall = recall_score(y_test_fold, y_pred_fold, average='macro')\n",
    "    recall_scores.append(recall)\n",
    "    \n",
    "    f1 = f1_score(y_test_fold, y_pred_fold, average='macro')\n",
    "    f1_scores.append(f1)\n",
    "    \n",
    "    # 如果模型是二分类模型，并且你已经有了模型预测的概率，可以计算ROC AUC\n",
    "    if len(set(y_test_fold)) == 2:\n",
    "        y_scores_fold = model.predict_proba(X_test_fold)[:, 1]  # 获取正类的概率\n",
    "        roc_auc = roc_auc_score(y_test_fold, y_scores_fold)\n",
    "        roc_auc_scores.append(roc_auc)\n",
    "    \n",
    "    # 计算Specificity\n",
    "    conf_mat_fold = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "    tn, fp, fn, tp = conf_mat_fold.ravel()\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    specificity_scores.append(specificity)\n",
    "\n",
    "# 输出每个指标的平均值\n",
    "print(\"Average Accuracy:\", sum(accuracy_scores) / len(accuracy_scores))\n",
    "print(\"Average Precision:\", sum(precision_scores) / len(precision_scores))\n",
    "print(\"Average Recall:\", sum(recall_scores) / len(recall_scores))\n",
    "print(\"Average F1 Score:\", sum(f1_scores) / len(f1_scores))\n",
    "if roc_auc_scores:\n",
    "    print(\"Average ROC AUC:\", sum(roc_auc_scores) / len(roc_auc_scores))\n",
    "print(\"Average Specificity:\", sum(specificity_scores) / len(specificity_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0af5e386-a291-4618-abd9-ee2888a8e164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.8647879578884259\n",
      "Average Precision: 0.8648595866405895\n",
      "Average Recall: 0.8647734821810886\n",
      "Average F1 Score: 0.8646644121036513\n",
      "Average ROC AUC: 0.9362376349547198\n",
      "Average Specificity: 0.866438337138514\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "\n",
    "model = LogisticRegression(max_iter=2000)\n",
    "\n",
    "# 创建 KFold 交叉验证分割器\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# 初始化指标列表\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "roc_auc_scores = []\n",
    "specificity_scores = []\n",
    "\n",
    "# 进行10×10交叉验证\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    # 分割数据，使用 .iloc 来根据行索引选择数据\n",
    "    X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    \n",
    "    # 训练模型\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # 进行预测\n",
    "    y_pred_fold = model.predict(X_test_fold)\n",
    "    \n",
    "    # 计算并存储每个指标\n",
    "    accuracy = accuracy_score(y_test_fold, y_pred_fold)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    \n",
    "    precision = precision_score(y_test_fold, y_pred_fold, average='macro')\n",
    "    precision_scores.append(precision)\n",
    "    \n",
    "    recall = recall_score(y_test_fold, y_pred_fold, average='macro')\n",
    "    recall_scores.append(recall)\n",
    "    \n",
    "    f1 = f1_score(y_test_fold, y_pred_fold, average='macro')\n",
    "    f1_scores.append(f1)\n",
    "    \n",
    "    # 如果模型是二分类模型，并且你已经有了模型预测的概率，可以计算ROC AUC\n",
    "    if len(set(y_test_fold)) == 2:\n",
    "        y_scores_fold = model.predict_proba(X_test_fold)[:, 1]  # 获取正类的概率\n",
    "        roc_auc = roc_auc_score(y_test_fold, y_scores_fold)\n",
    "        roc_auc_scores.append(roc_auc)\n",
    "    \n",
    "    # 计算Specificity\n",
    "    conf_mat_fold = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "    tn, fp, fn, tp = conf_mat_fold.ravel()\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    specificity_scores.append(specificity)\n",
    "\n",
    "# 输出每个指标的平均值\n",
    "print(\"Average Accuracy:\", sum(accuracy_scores) / len(accuracy_scores))\n",
    "print(\"Average Precision:\", sum(precision_scores) / len(precision_scores))\n",
    "print(\"Average Recall:\", sum(recall_scores) / len(recall_scores))\n",
    "print(\"Average F1 Score:\", sum(f1_scores) / len(f1_scores))\n",
    "if roc_auc_scores:\n",
    "    print(\"Average ROC AUC:\", sum(roc_auc_scores) / len(roc_auc_scores))\n",
    "print(\"Average Specificity:\", sum(specificity_scores) / len(specificity_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0243f633-d9c6-468e-ae37-edcca44470cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.8989048732749954\n",
      "Average Precision: 0.9015570193233602\n",
      "Average Recall: 0.8988013422480451\n",
      "Average F1 Score: 0.8986464801382441\n",
      "Average ROC AUC: 0.9589081165012405\n",
      "Average Specificity: 0.8582913458942153\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "# 创建 KFold 交叉验证分割器\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# 初始化指标列表\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "roc_auc_scores = []\n",
    "specificity_scores = []\n",
    "\n",
    "# 进行10×10交叉验证\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    # 分割数据，使用 .iloc 来根据行索引选择数据\n",
    "    X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    \n",
    "    # 训练模型\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # 进行预测\n",
    "    y_pred_fold = model.predict(X_test_fold)\n",
    "    \n",
    "    # 计算并存储每个指标\n",
    "    accuracy = accuracy_score(y_test_fold, y_pred_fold)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    \n",
    "    precision = precision_score(y_test_fold, y_pred_fold, average='macro')\n",
    "    precision_scores.append(precision)\n",
    "    \n",
    "    recall = recall_score(y_test_fold, y_pred_fold, average='macro')\n",
    "    recall_scores.append(recall)\n",
    "    \n",
    "    f1 = f1_score(y_test_fold, y_pred_fold, average='macro')\n",
    "    f1_scores.append(f1)\n",
    "    \n",
    "    # 如果模型是二分类模型，并且你已经有了模型预测的概率，可以计算ROC AUC\n",
    "    if len(set(y_test_fold)) == 2:\n",
    "        y_scores_fold = model.predict_proba(X_test_fold)[:, 1]  # 获取正类的概率\n",
    "        roc_auc = roc_auc_score(y_test_fold, y_scores_fold)\n",
    "        roc_auc_scores.append(roc_auc)\n",
    "    \n",
    "    # 计算Specificity\n",
    "    conf_mat_fold = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "    tn, fp, fn, tp = conf_mat_fold.ravel()\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    specificity_scores.append(specificity)\n",
    "\n",
    "# 输出每个指标的平均值\n",
    "print(\"Average Accuracy:\", sum(accuracy_scores) / len(accuracy_scores))\n",
    "print(\"Average Precision:\", sum(precision_scores) / len(precision_scores))\n",
    "print(\"Average Recall:\", sum(recall_scores) / len(recall_scores))\n",
    "print(\"Average F1 Score:\", sum(f1_scores) / len(f1_scores))\n",
    "if roc_auc_scores:\n",
    "    print(\"Average ROC AUC:\", sum(roc_auc_scores) / len(roc_auc_scores))\n",
    "print(\"Average Specificity:\", sum(specificity_scores) / len(specificity_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b852bcd-01d3-4f24-8cdf-52f813c86f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.9037182433201844\n",
      "Average Precision: 0.9036180162084939\n",
      "Average Recall: 0.9037393343428599\n",
      "Average F1 Score: 0.9036439630367832\n",
      "Average ROC AUC: 0.967792142877457\n",
      "Average Specificity: 0.9060043566325824\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# 创建 KFold 交叉验证分割器\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# 初始化指标列表\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "roc_auc_scores = []\n",
    "specificity_scores = []\n",
    "\n",
    "# 进行10×10交叉验证\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    # 分割数据，使用 .iloc 来根据行索引选择数据\n",
    "    X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    \n",
    "    # 训练模型\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # 进行预测\n",
    "    y_pred_fold = model.predict(X_test_fold)\n",
    "    \n",
    "    # 计算并存储每个指标\n",
    "    accuracy = accuracy_score(y_test_fold, y_pred_fold)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    \n",
    "    precision = precision_score(y_test_fold, y_pred_fold, average='macro')\n",
    "    precision_scores.append(precision)\n",
    "    \n",
    "    recall = recall_score(y_test_fold, y_pred_fold, average='macro')\n",
    "    recall_scores.append(recall)\n",
    "    \n",
    "    f1 = f1_score(y_test_fold, y_pred_fold, average='macro')\n",
    "    f1_scores.append(f1)\n",
    "    \n",
    "    # 如果模型是二分类模型，并且你已经有了模型预测的概率，可以计算ROC AUC\n",
    "    if len(set(y_test_fold)) == 2:\n",
    "        y_scores_fold = model.predict_proba(X_test_fold)[:, 1]  # 获取正类的概率\n",
    "        roc_auc = roc_auc_score(y_test_fold, y_scores_fold)\n",
    "        roc_auc_scores.append(roc_auc)\n",
    "    \n",
    "    # 计算Specificity\n",
    "    conf_mat_fold = confusion_matrix(y_test_fold, y_pred_fold)\n",
    "    tn, fp, fn, tp = conf_mat_fold.ravel()\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    specificity_scores.append(specificity)\n",
    "\n",
    "# 输出每个指标的平均值\n",
    "print(\"Average Accuracy:\", sum(accuracy_scores) / len(accuracy_scores))\n",
    "print(\"Average Precision:\", sum(precision_scores) / len(precision_scores))\n",
    "print(\"Average Recall:\", sum(recall_scores) / len(recall_scores))\n",
    "print(\"Average F1 Score:\", sum(f1_scores) / len(f1_scores))\n",
    "if roc_auc_scores:\n",
    "    print(\"Average ROC AUC:\", sum(roc_auc_scores) / len(roc_auc_scores))\n",
    "print(\"Average Specificity:\", sum(specificity_scores) / len(specificity_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9eed3ae-8035-408e-b222-38981c083fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Best parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 400}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91      7163\n",
      "           1       0.91      0.91      0.91      7170\n",
      "\n",
      "    accuracy                           0.91     14333\n",
      "   macro avg       0.91      0.91      0.91     14333\n",
      "weighted avg       0.91      0.91      0.91     14333\n",
      "\n",
      "[[6505  658]\n",
      " [ 665 6505]]\n",
      "Average Accuracy: 0.9076955278029721\n",
      "Average Precision: 0.9076957443051041\n",
      "Average Recall: 0.9076957443051041\n",
      "Average F1 Score: 0.9076955278029721\n",
      "Average ROC AUC: 1.0\n",
      "Average Specificity: 0.9081390478849644\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n",
    "\n",
    "# 创建随机森林分类器\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# 定义参数网格\n",
    "param_grid = {\n",
    "    'n_estimators': [400],\n",
    "    'max_depth': [None],\n",
    "    'min_samples_split': [2],\n",
    "    'min_samples_leaf': [1]\n",
    "}\n",
    "\n",
    "# 创建 KFold 交叉验证分割器\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# 设置网格搜索，使用 KFold 交叉验证，并指定refit参数\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=kf, scoring='accuracy', refit=True, verbose=1)\n",
    "\n",
    "# 执行网格搜索\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 输出最佳参数\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "\n",
    "# 获取最佳模型\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# 使用最佳模型进行交叉验证预测\n",
    "y_pred = cross_val_predict(best_rf, X_train, y_train, cv=kf)\n",
    "\n",
    "# 计算所有指标的平均值\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "precision = precision_score(y_train, y_pred, average='macro')\n",
    "recall = recall_score(y_train, y_pred, average='macro')\n",
    "f1 = f1_score(y_train, y_pred, average='macro')\n",
    "\n",
    "# 如果是二分类问题，计算ROC AUC\n",
    "if len(set(y_train)) == 2:\n",
    "    y_scores = best_rf.predict_proba(X_train)[:, 1]\n",
    "    roc_auc = roc_auc_score(y_train, y_scores)\n",
    "else:\n",
    "    roc_auc = None  # 对于多分类问题，ROC AUC需要不同的处理\n",
    "\n",
    "# 打印分类报告\n",
    "print(classification_report(y_train, y_pred))\n",
    "\n",
    "# 打印混淆矩阵\n",
    "conf_mat = confusion_matrix(y_train, y_pred)\n",
    "print(conf_mat)\n",
    "\n",
    "# 输出每个指标的平均值\n",
    "print(\"Average Accuracy:\", accuracy)\n",
    "print(\"Average Precision:\", precision)\n",
    "print(\"Average Recall:\", recall)\n",
    "print(\"Average F1 Score:\", f1)\n",
    "if roc_auc is not None:\n",
    "    print(\"Average ROC AUC:\", roc_auc)\n",
    "\n",
    "# 计算Specificity\n",
    "tn, fp, fn, tp = conf_mat.ravel()\n",
    "specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "print(\"Average Specificity:\", specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cf8a8e5-98d7-43b5-9267-f55bbea09526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Feature  Importance\n",
      "61  EQ-5D-5L-5    0.045289\n",
      "56  FHS-SF10_R    0.043995\n",
      "52   FHS-SF6_R    0.041375\n",
      "55   FHS-SF9_R    0.029103\n",
      "83    Fitness3    0.027131\n",
      "..         ...         ...\n",
      "5       zhaiwu    0.004634\n",
      "70  HLS-SF12-9    0.004608\n",
      "59  EQ-5D-5L-3    0.004503\n",
      "14       smoke    0.003650\n",
      "3     chaiqian    0.001723\n",
      "\n",
      "[96 rows x 2 columns]\n",
      "       Feature  Importance\n",
      "61  EQ-5D-5L-5    0.045289\n",
      "56  FHS-SF10_R    0.043995\n",
      "52   FHS-SF6_R    0.041375\n",
      "55   FHS-SF9_R    0.029103\n",
      "83    Fitness3    0.027131\n",
      "88     Stress2    0.023362\n",
      "87     Stress1    0.023203\n",
      "19      BFI3_R    0.021997\n",
      "49     FHS-SF3    0.020715\n",
      "48     FHS-SF2    0.020373\n"
     ]
    }
   ],
   "source": [
    "# 获取特征重要性\n",
    "feature_importances = best_rf.feature_importances_\n",
    "\n",
    "# 排序特征\n",
    "feature_names = X.columns\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# 打印特征重要性排序\n",
    "print(importance_df)\n",
    "print(importance_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "915c0790-5e3d-4ba4-a112-938f4578cdaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Feature  Importance  Cumulative Importance\n",
      "61          EQ-5D-5L-5    0.045289               0.045289\n",
      "56          FHS-SF10_R    0.043995               0.089284\n",
      "52           FHS-SF6_R    0.041375               0.130659\n",
      "55           FHS-SF9_R    0.029103               0.159762\n",
      "83            Fitness3    0.027131               0.186893\n",
      "88             Stress2    0.023362               0.210255\n",
      "87             Stress1    0.023203               0.233458\n",
      "19              BFI3_R    0.021997               0.255455\n",
      "49             FHS-SF3    0.020715               0.276171\n",
      "48             FHS-SF2    0.020373               0.296544\n",
      "85            Fitness5    0.019996               0.316540\n",
      "23              BFI7_R    0.018285               0.334825\n",
      "47             FHS-SF1    0.017888               0.352712\n",
      "10            marriage    0.017855               0.370568\n",
      "16                 BMI    0.016069               0.386637\n",
      "50             FHS-SF4    0.015761               0.402397\n",
      "12          brosis_Num    0.015231               0.417628\n",
      "40              NGSES2    0.014930               0.432558\n",
      "82            Fitness2    0.014831               0.447388\n",
      "51             FHS-SF5    0.014778               0.462166\n",
      "89             Stress3    0.014438               0.476604\n",
      "60          EQ-5D-5L-4    0.013812               0.490416\n",
      "8                  age    0.012847               0.503263\n",
      "90  Emontion_regulate1    0.011471               0.514734\n",
      "29               PSSS3    0.011087               0.525821\n",
      "91  Emontion_regulate2    0.010631               0.536452\n",
      "53             FHS-SF7    0.010252               0.546704\n",
      "30               PSSS4    0.010088               0.556792\n",
      "81            Fitness1    0.009960               0.566752\n",
      "4          home_mianji    0.009774               0.576526\n",
      "84            Fitness4    0.009305               0.585831\n",
      "66          HLS-SF12-5    0.009089               0.594920\n",
      "13                ocup    0.009047               0.603967\n",
      "6        family_income    0.008984               0.612951\n",
      "11           child_Num    0.008964               0.621915\n",
      "17              BFI1_R    0.008665               0.630580\n",
      "9                  edu    0.008595               0.639175\n",
      "80             EBS-SF7    0.008298               0.647472\n",
      "92  Emontion_regulate3    0.008296               0.655769\n",
      "93  Emontion_regulate4    0.008258               0.664026\n",
      "86            Fitness6    0.008211               0.672237\n",
      "2              homeNum    0.007796               0.680033\n",
      "44              NGSES6    0.007793               0.687826\n",
      "95  Emontion_regulate6    0.007740               0.695566\n",
      "39              NGSES1    0.007720               0.703286\n",
      "34               PSSS8    0.007567               0.710852\n",
      "94  Emontion_regulate5    0.007457               0.718310\n",
      "21              BFI5_R    0.007437               0.725747\n",
      "22                BFI6    0.007299               0.733046\n",
      "20              BFI4_R    0.007224               0.740270\n",
      "18                BFI2    0.007217               0.747486\n",
      "63          HLS-SF12-2    0.007202               0.754689\n",
      "7               gender    0.007151               0.761840\n",
      "24                BFI8    0.007019               0.768859\n",
      "67          HLS-SF12-6    0.006857               0.775716\n",
      "43              NGSES5    0.006789               0.782505\n",
      "41              NGSES3    0.006553               0.789058\n",
      "28               PSSS2    0.006526               0.795585\n"
     ]
    }
   ],
   "source": [
    "importance_df['Cumulative Importance'] = importance_df['Importance'].cumsum()\n",
    "threshold = 0.8  # 这里设定80%的阈值\n",
    "N = importance_df[importance_df['Cumulative Importance'] <= threshold].shape[0]\n",
    "# 打印特征重要性排序\n",
    "pd.options.display.max_rows = None\n",
    "print(importance_df.head(N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21931eb1-82a8-45ee-8469-fa0147067101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_rf_itemdep.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "dump(best_rf, 'best_rf_itemdep.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ec39e4a-b1bf-452c-bb0c-8d74df0cd9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 45 candidates, totalling 450 fits\n",
      "[LightGBM] [Info] Number of positive: 6450, number of negative: 6449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002200 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000155\n",
      "[LightGBM] [Info] Start training from score 0.000155\n",
      "[LightGBM] [Info] Number of positive: 6472, number of negative: 6427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002167 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501744 -> initscore=0.006977\n",
      "[LightGBM] [Info] Start training from score 0.006977\n",
      "[LightGBM] [Info] Number of positive: 6455, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002258 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500426 -> initscore=0.001706\n",
      "[LightGBM] [Info] Start training from score 0.001706\n",
      "[LightGBM] [Info] Number of positive: 6481, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002188 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502403 -> initscore=0.009612\n",
      "[LightGBM] [Info] Start training from score 0.009612\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002112 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002225 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6393, number of negative: 6507\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002194 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495581 -> initscore=-0.017675\n",
      "[LightGBM] [Info] Start training from score -0.017675\n",
      "[LightGBM] [Info] Number of positive: 6457, number of negative: 6443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002250 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500543 -> initscore=0.002171\n",
      "[LightGBM] [Info] Start training from score 0.002171\n",
      "[LightGBM] [Info] Number of positive: 6448, number of negative: 6452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002158 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499845 -> initscore=-0.000620\n",
      "[LightGBM] [Info] Start training from score -0.000620\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002052 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6450, number of negative: 6449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002296 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000155\n",
      "[LightGBM] [Info] Start training from score 0.000155\n",
      "[LightGBM] [Info] Number of positive: 6472, number of negative: 6427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002208 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501744 -> initscore=0.006977\n",
      "[LightGBM] [Info] Start training from score 0.006977\n",
      "[LightGBM] [Info] Number of positive: 6455, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002116 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500426 -> initscore=0.001706\n",
      "[LightGBM] [Info] Start training from score 0.001706\n",
      "[LightGBM] [Info] Number of positive: 6481, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002273 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502403 -> initscore=0.009612\n",
      "[LightGBM] [Info] Start training from score 0.009612\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002220 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002100 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6393, number of negative: 6507\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003467 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495581 -> initscore=-0.017675\n",
      "[LightGBM] [Info] Start training from score -0.017675\n",
      "[LightGBM] [Info] Number of positive: 6457, number of negative: 6443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002181 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500543 -> initscore=0.002171\n",
      "[LightGBM] [Info] Start training from score 0.002171\n",
      "[LightGBM] [Info] Number of positive: 6448, number of negative: 6452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002350 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499845 -> initscore=-0.000620\n",
      "[LightGBM] [Info] Start training from score -0.000620\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002066 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6450, number of negative: 6449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002234 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000155\n",
      "[LightGBM] [Info] Start training from score 0.000155\n",
      "[LightGBM] [Info] Number of positive: 6472, number of negative: 6427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002157 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501744 -> initscore=0.006977\n",
      "[LightGBM] [Info] Start training from score 0.006977\n",
      "[LightGBM] [Info] Number of positive: 6455, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003221 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500426 -> initscore=0.001706\n",
      "[LightGBM] [Info] Start training from score 0.001706\n",
      "[LightGBM] [Info] Number of positive: 6481, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002229 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502403 -> initscore=0.009612\n",
      "[LightGBM] [Info] Start training from score 0.009612\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002168 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002191 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6393, number of negative: 6507\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002160 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495581 -> initscore=-0.017675\n",
      "[LightGBM] [Info] Start training from score -0.017675\n",
      "[LightGBM] [Info] Number of positive: 6457, number of negative: 6443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002678 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500543 -> initscore=0.002171\n",
      "[LightGBM] [Info] Start training from score 0.002171\n",
      "[LightGBM] [Info] Number of positive: 6448, number of negative: 6452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003598 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499845 -> initscore=-0.000620\n",
      "[LightGBM] [Info] Start training from score -0.000620\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005225 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6450, number of negative: 6449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002090 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000155\n",
      "[LightGBM] [Info] Start training from score 0.000155\n",
      "[LightGBM] [Info] Number of positive: 6472, number of negative: 6427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002157 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501744 -> initscore=0.006977\n",
      "[LightGBM] [Info] Start training from score 0.006977\n",
      "[LightGBM] [Info] Number of positive: 6455, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002158 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500426 -> initscore=0.001706\n",
      "[LightGBM] [Info] Start training from score 0.001706\n",
      "[LightGBM] [Info] Number of positive: 6481, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002240 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502403 -> initscore=0.009612\n",
      "[LightGBM] [Info] Start training from score 0.009612\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002082 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002047 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6393, number of negative: 6507\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002195 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495581 -> initscore=-0.017675\n",
      "[LightGBM] [Info] Start training from score -0.017675\n",
      "[LightGBM] [Info] Number of positive: 6457, number of negative: 6443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002014 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500543 -> initscore=0.002171\n",
      "[LightGBM] [Info] Start training from score 0.002171\n",
      "[LightGBM] [Info] Number of positive: 6448, number of negative: 6452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002281 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499845 -> initscore=-0.000620\n",
      "[LightGBM] [Info] Start training from score -0.000620\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002190 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6450, number of negative: 6449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002083 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000155\n",
      "[LightGBM] [Info] Start training from score 0.000155\n",
      "[LightGBM] [Info] Number of positive: 6472, number of negative: 6427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002119 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501744 -> initscore=0.006977\n",
      "[LightGBM] [Info] Start training from score 0.006977\n",
      "[LightGBM] [Info] Number of positive: 6455, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003172 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500426 -> initscore=0.001706\n",
      "[LightGBM] [Info] Start training from score 0.001706\n",
      "[LightGBM] [Info] Number of positive: 6481, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002222 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502403 -> initscore=0.009612\n",
      "[LightGBM] [Info] Start training from score 0.009612\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002039 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002367 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6393, number of negative: 6507\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002102 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495581 -> initscore=-0.017675\n",
      "[LightGBM] [Info] Start training from score -0.017675\n",
      "[LightGBM] [Info] Number of positive: 6457, number of negative: 6443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002269 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500543 -> initscore=0.002171\n",
      "[LightGBM] [Info] Start training from score 0.002171\n",
      "[LightGBM] [Info] Number of positive: 6448, number of negative: 6452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002371 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499845 -> initscore=-0.000620\n",
      "[LightGBM] [Info] Start training from score -0.000620\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002179 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6450, number of negative: 6449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002358 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000155\n",
      "[LightGBM] [Info] Start training from score 0.000155\n",
      "[LightGBM] [Info] Number of positive: 6472, number of negative: 6427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002161 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501744 -> initscore=0.006977\n",
      "[LightGBM] [Info] Start training from score 0.006977\n",
      "[LightGBM] [Info] Number of positive: 6455, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005475 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500426 -> initscore=0.001706\n",
      "[LightGBM] [Info] Start training from score 0.001706\n",
      "[LightGBM] [Info] Number of positive: 6481, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002309 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502403 -> initscore=0.009612\n",
      "[LightGBM] [Info] Start training from score 0.009612\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002263 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002050 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6393, number of negative: 6507\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002083 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495581 -> initscore=-0.017675\n",
      "[LightGBM] [Info] Start training from score -0.017675\n",
      "[LightGBM] [Info] Number of positive: 6457, number of negative: 6443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003108 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500543 -> initscore=0.002171\n",
      "[LightGBM] [Info] Start training from score 0.002171\n",
      "[LightGBM] [Info] Number of positive: 6448, number of negative: 6452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002187 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499845 -> initscore=-0.000620\n",
      "[LightGBM] [Info] Start training from score -0.000620\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002199 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6450, number of negative: 6449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002183 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000155\n",
      "[LightGBM] [Info] Start training from score 0.000155\n",
      "[LightGBM] [Info] Number of positive: 6472, number of negative: 6427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002158 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501744 -> initscore=0.006977\n",
      "[LightGBM] [Info] Start training from score 0.006977\n",
      "[LightGBM] [Info] Number of positive: 6455, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002073 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500426 -> initscore=0.001706\n",
      "[LightGBM] [Info] Start training from score 0.001706\n",
      "[LightGBM] [Info] Number of positive: 6481, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002063 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502403 -> initscore=0.009612\n",
      "[LightGBM] [Info] Start training from score 0.009612\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002134 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002066 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6393, number of negative: 6507\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002131 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495581 -> initscore=-0.017675\n",
      "[LightGBM] [Info] Start training from score -0.017675\n",
      "[LightGBM] [Info] Number of positive: 6457, number of negative: 6443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002252 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500543 -> initscore=0.002171\n",
      "[LightGBM] [Info] Start training from score 0.002171\n",
      "[LightGBM] [Info] Number of positive: 6448, number of negative: 6452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002152 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499845 -> initscore=-0.000620\n",
      "[LightGBM] [Info] Start training from score -0.000620\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002129 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6450, number of negative: 6449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002129 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000155\n",
      "[LightGBM] [Info] Start training from score 0.000155\n",
      "[LightGBM] [Info] Number of positive: 6472, number of negative: 6427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002091 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501744 -> initscore=0.006977\n",
      "[LightGBM] [Info] Start training from score 0.006977\n",
      "[LightGBM] [Info] Number of positive: 6455, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002139 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500426 -> initscore=0.001706\n",
      "[LightGBM] [Info] Start training from score 0.001706\n",
      "[LightGBM] [Info] Number of positive: 6481, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002341 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502403 -> initscore=0.009612\n",
      "[LightGBM] [Info] Start training from score 0.009612\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002146 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002082 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6393, number of negative: 6507\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002159 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495581 -> initscore=-0.017675\n",
      "[LightGBM] [Info] Start training from score -0.017675\n",
      "[LightGBM] [Info] Number of positive: 6457, number of negative: 6443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002211 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500543 -> initscore=0.002171\n",
      "[LightGBM] [Info] Start training from score 0.002171\n",
      "[LightGBM] [Info] Number of positive: 6448, number of negative: 6452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002346 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499845 -> initscore=-0.000620\n",
      "[LightGBM] [Info] Start training from score -0.000620\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002138 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6450, number of negative: 6449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002119 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000155\n",
      "[LightGBM] [Info] Start training from score 0.000155\n",
      "[LightGBM] [Info] Number of positive: 6472, number of negative: 6427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002082 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501744 -> initscore=0.006977\n",
      "[LightGBM] [Info] Start training from score 0.006977\n",
      "[LightGBM] [Info] Number of positive: 6455, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002120 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500426 -> initscore=0.001706\n",
      "[LightGBM] [Info] Start training from score 0.001706\n",
      "[LightGBM] [Info] Number of positive: 6481, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002212 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502403 -> initscore=0.009612\n",
      "[LightGBM] [Info] Start training from score 0.009612\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002431 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002117 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6393, number of negative: 6507\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002029 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495581 -> initscore=-0.017675\n",
      "[LightGBM] [Info] Start training from score -0.017675\n",
      "[LightGBM] [Info] Number of positive: 6457, number of negative: 6443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002396 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500543 -> initscore=0.002171\n",
      "[LightGBM] [Info] Start training from score 0.002171\n",
      "[LightGBM] [Info] Number of positive: 6448, number of negative: 6452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002221 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499845 -> initscore=-0.000620\n",
      "[LightGBM] [Info] Start training from score -0.000620\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002043 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6450, number of negative: 6449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002243 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000155\n",
      "[LightGBM] [Info] Start training from score 0.000155\n",
      "[LightGBM] [Info] Number of positive: 6472, number of negative: 6427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002152 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501744 -> initscore=0.006977\n",
      "[LightGBM] [Info] Start training from score 0.006977\n",
      "[LightGBM] [Info] Number of positive: 6455, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003231 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500426 -> initscore=0.001706\n",
      "[LightGBM] [Info] Start training from score 0.001706\n",
      "[LightGBM] [Info] Number of positive: 6481, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002286 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502403 -> initscore=0.009612\n",
      "[LightGBM] [Info] Start training from score 0.009612\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002124 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002152 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6393, number of negative: 6507\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002096 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495581 -> initscore=-0.017675\n",
      "[LightGBM] [Info] Start training from score -0.017675\n",
      "[LightGBM] [Info] Number of positive: 6457, number of negative: 6443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002160 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500543 -> initscore=0.002171\n",
      "[LightGBM] [Info] Start training from score 0.002171\n",
      "[LightGBM] [Info] Number of positive: 6448, number of negative: 6452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002188 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499845 -> initscore=-0.000620\n",
      "[LightGBM] [Info] Start training from score -0.000620\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002112 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6450, number of negative: 6449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002097 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000155\n",
      "[LightGBM] [Info] Start training from score 0.000155\n",
      "[LightGBM] [Info] Number of positive: 6472, number of negative: 6427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002140 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501744 -> initscore=0.006977\n",
      "[LightGBM] [Info] Start training from score 0.006977\n",
      "[LightGBM] [Info] Number of positive: 6455, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002215 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500426 -> initscore=0.001706\n",
      "[LightGBM] [Info] Start training from score 0.001706\n",
      "[LightGBM] [Info] Number of positive: 6481, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002309 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502403 -> initscore=0.009612\n",
      "[LightGBM] [Info] Start training from score 0.009612\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002189 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002185 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6393, number of negative: 6507\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003721 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495581 -> initscore=-0.017675\n",
      "[LightGBM] [Info] Start training from score -0.017675\n",
      "[LightGBM] [Info] Number of positive: 6457, number of negative: 6443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003557 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500543 -> initscore=0.002171\n",
      "[LightGBM] [Info] Start training from score 0.002171\n",
      "[LightGBM] [Info] Number of positive: 6448, number of negative: 6452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002224 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499845 -> initscore=-0.000620\n",
      "[LightGBM] [Info] Start training from score -0.000620\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002536 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6450, number of negative: 6449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002205 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000155\n",
      "[LightGBM] [Info] Start training from score 0.000155\n",
      "[LightGBM] [Info] Number of positive: 6472, number of negative: 6427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002078 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501744 -> initscore=0.006977\n",
      "[LightGBM] [Info] Start training from score 0.006977\n",
      "[LightGBM] [Info] Number of positive: 6455, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002138 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500426 -> initscore=0.001706\n",
      "[LightGBM] [Info] Start training from score 0.001706\n",
      "[LightGBM] [Info] Number of positive: 6481, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002124 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502403 -> initscore=0.009612\n",
      "[LightGBM] [Info] Start training from score 0.009612\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002351 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002251 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6393, number of negative: 6507\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002317 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495581 -> initscore=-0.017675\n",
      "[LightGBM] [Info] Start training from score -0.017675\n",
      "[LightGBM] [Info] Number of positive: 6457, number of negative: 6443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002117 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500543 -> initscore=0.002171\n",
      "[LightGBM] [Info] Start training from score 0.002171\n",
      "[LightGBM] [Info] Number of positive: 6448, number of negative: 6452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002318 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499845 -> initscore=-0.000620\n",
      "[LightGBM] [Info] Start training from score -0.000620\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002173 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6450, number of negative: 6449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002040 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000155\n",
      "[LightGBM] [Info] Start training from score 0.000155\n",
      "[LightGBM] [Info] Number of positive: 6472, number of negative: 6427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002164 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501744 -> initscore=0.006977\n",
      "[LightGBM] [Info] Start training from score 0.006977\n",
      "[LightGBM] [Info] Number of positive: 6455, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002177 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500426 -> initscore=0.001706\n",
      "[LightGBM] [Info] Start training from score 0.001706\n",
      "[LightGBM] [Info] Number of positive: 6481, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002197 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502403 -> initscore=0.009612\n",
      "[LightGBM] [Info] Start training from score 0.009612\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002532 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6393, number of negative: 6507\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002071 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495581 -> initscore=-0.017675\n",
      "[LightGBM] [Info] Start training from score -0.017675\n",
      "[LightGBM] [Info] Number of positive: 6457, number of negative: 6443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002291 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500543 -> initscore=0.002171\n",
      "[LightGBM] [Info] Start training from score 0.002171\n",
      "[LightGBM] [Info] Number of positive: 6448, number of negative: 6452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002466 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499845 -> initscore=-0.000620\n",
      "[LightGBM] [Info] Start training from score -0.000620\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002160 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6450, number of negative: 6449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002191 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000155\n",
      "[LightGBM] [Info] Start training from score 0.000155\n",
      "[LightGBM] [Info] Number of positive: 6472, number of negative: 6427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002131 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501744 -> initscore=0.006977\n",
      "[LightGBM] [Info] Start training from score 0.006977\n",
      "[LightGBM] [Info] Number of positive: 6455, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002270 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500426 -> initscore=0.001706\n",
      "[LightGBM] [Info] Start training from score 0.001706\n",
      "[LightGBM] [Info] Number of positive: 6481, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002184 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502403 -> initscore=0.009612\n",
      "[LightGBM] [Info] Start training from score 0.009612\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002079 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002133 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6393, number of negative: 6507\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002191 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495581 -> initscore=-0.017675\n",
      "[LightGBM] [Info] Start training from score -0.017675\n",
      "[LightGBM] [Info] Number of positive: 6457, number of negative: 6443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002197 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500543 -> initscore=0.002171\n",
      "[LightGBM] [Info] Start training from score 0.002171\n",
      "[LightGBM] [Info] Number of positive: 6448, number of negative: 6452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002261 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499845 -> initscore=-0.000620\n",
      "[LightGBM] [Info] Start training from score -0.000620\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002296 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6450, number of negative: 6449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002244 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000155\n",
      "[LightGBM] [Info] Start training from score 0.000155\n",
      "[LightGBM] [Info] Number of positive: 6472, number of negative: 6427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002146 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501744 -> initscore=0.006977\n",
      "[LightGBM] [Info] Start training from score 0.006977\n",
      "[LightGBM] [Info] Number of positive: 6455, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002184 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500426 -> initscore=0.001706\n",
      "[LightGBM] [Info] Start training from score 0.001706\n",
      "[LightGBM] [Info] Number of positive: 6481, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002217 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502403 -> initscore=0.009612\n",
      "[LightGBM] [Info] Start training from score 0.009612\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002220 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002198 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6393, number of negative: 6507\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002236 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495581 -> initscore=-0.017675\n",
      "[LightGBM] [Info] Start training from score -0.017675\n",
      "[LightGBM] [Info] Number of positive: 6457, number of negative: 6443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002260 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500543 -> initscore=0.002171\n",
      "[LightGBM] [Info] Start training from score 0.002171\n",
      "[LightGBM] [Info] Number of positive: 6448, number of negative: 6452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002054 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499845 -> initscore=-0.000620\n",
      "[LightGBM] [Info] Start training from score -0.000620\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002106 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6450, number of negative: 6449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002207 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000155\n",
      "[LightGBM] [Info] Start training from score 0.000155\n",
      "[LightGBM] [Info] Number of positive: 6472, number of negative: 6427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002145 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501744 -> initscore=0.006977\n",
      "[LightGBM] [Info] Start training from score 0.006977\n",
      "[LightGBM] [Info] Number of positive: 6455, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002032 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500426 -> initscore=0.001706\n",
      "[LightGBM] [Info] Start training from score 0.001706\n",
      "[LightGBM] [Info] Number of positive: 6481, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002073 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502403 -> initscore=0.009612\n",
      "[LightGBM] [Info] Start training from score 0.009612\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001975 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002154 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6393, number of negative: 6507\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001857 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495581 -> initscore=-0.017675\n",
      "[LightGBM] [Info] Start training from score -0.017675\n",
      "[LightGBM] [Info] Number of positive: 6457, number of negative: 6443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002100 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500543 -> initscore=0.002171\n",
      "[LightGBM] [Info] Start training from score 0.002171\n",
      "[LightGBM] [Info] Number of positive: 6448, number of negative: 6452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002125 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499845 -> initscore=-0.000620\n",
      "[LightGBM] [Info] Start training from score -0.000620\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001967 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6450, number of negative: 6449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002003 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000155\n",
      "[LightGBM] [Info] Start training from score 0.000155\n",
      "[LightGBM] [Info] Number of positive: 6472, number of negative: 6427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002476 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501744 -> initscore=0.006977\n",
      "[LightGBM] [Info] Start training from score 0.006977\n",
      "[LightGBM] [Info] Number of positive: 6455, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002117 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500426 -> initscore=0.001706\n",
      "[LightGBM] [Info] Start training from score 0.001706\n",
      "[LightGBM] [Info] Number of positive: 6481, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002154 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502403 -> initscore=0.009612\n",
      "[LightGBM] [Info] Start training from score 0.009612\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002086 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001986 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6393, number of negative: 6507\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002246 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495581 -> initscore=-0.017675\n",
      "[LightGBM] [Info] Start training from score -0.017675\n",
      "[LightGBM] [Info] Number of positive: 6457, number of negative: 6443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001987 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500543 -> initscore=0.002171\n",
      "[LightGBM] [Info] Start training from score 0.002171\n",
      "[LightGBM] [Info] Number of positive: 6448, number of negative: 6452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002146 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499845 -> initscore=-0.000620\n",
      "[LightGBM] [Info] Start training from score -0.000620\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002427 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6450, number of negative: 6449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002193 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000155\n",
      "[LightGBM] [Info] Start training from score 0.000155\n",
      "[LightGBM] [Info] Number of positive: 6472, number of negative: 6427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001891 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501744 -> initscore=0.006977\n",
      "[LightGBM] [Info] Start training from score 0.006977\n",
      "[LightGBM] [Info] Number of positive: 6455, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002103 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500426 -> initscore=0.001706\n",
      "[LightGBM] [Info] Start training from score 0.001706\n",
      "[LightGBM] [Info] Number of positive: 6481, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002133 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502403 -> initscore=0.009612\n",
      "[LightGBM] [Info] Start training from score 0.009612\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001994 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002134 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6393, number of negative: 6507\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002054 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495581 -> initscore=-0.017675\n",
      "[LightGBM] [Info] Start training from score -0.017675\n",
      "[LightGBM] [Info] Number of positive: 6457, number of negative: 6443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002189 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500543 -> initscore=0.002171\n",
      "[LightGBM] [Info] Start training from score 0.002171\n",
      "[LightGBM] [Info] Number of positive: 6448, number of negative: 6452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002953 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499845 -> initscore=-0.000620\n",
      "[LightGBM] [Info] Start training from score -0.000620\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002041 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6450, number of negative: 6449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002049 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000155\n",
      "[LightGBM] [Info] Start training from score 0.000155\n",
      "[LightGBM] [Info] Number of positive: 6472, number of negative: 6427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002128 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501744 -> initscore=0.006977\n",
      "[LightGBM] [Info] Start training from score 0.006977\n",
      "[LightGBM] [Info] Number of positive: 6455, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002027 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500426 -> initscore=0.001706\n",
      "[LightGBM] [Info] Start training from score 0.001706\n",
      "[LightGBM] [Info] Number of positive: 6481, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502403 -> initscore=0.009612\n",
      "[LightGBM] [Info] Start training from score 0.009612\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002050 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002130 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6393, number of negative: 6507\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001954 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495581 -> initscore=-0.017675\n",
      "[LightGBM] [Info] Start training from score -0.017675\n",
      "[LightGBM] [Info] Number of positive: 6457, number of negative: 6443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002144 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500543 -> initscore=0.002171\n",
      "[LightGBM] [Info] Start training from score 0.002171\n",
      "[LightGBM] [Info] Number of positive: 6448, number of negative: 6452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003292 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499845 -> initscore=-0.000620\n",
      "[LightGBM] [Info] Start training from score -0.000620\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002085 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6450, number of negative: 6449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002019 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000155\n",
      "[LightGBM] [Info] Start training from score 0.000155\n",
      "[LightGBM] [Info] Number of positive: 6472, number of negative: 6427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002100 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501744 -> initscore=0.006977\n",
      "[LightGBM] [Info] Start training from score 0.006977\n",
      "[LightGBM] [Info] Number of positive: 6455, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002076 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500426 -> initscore=0.001706\n",
      "[LightGBM] [Info] Start training from score 0.001706\n",
      "[LightGBM] [Info] Number of positive: 6481, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002228 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502403 -> initscore=0.009612\n",
      "[LightGBM] [Info] Start training from score 0.009612\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002032 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001983 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6393, number of negative: 6507\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002024 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495581 -> initscore=-0.017675\n",
      "[LightGBM] [Info] Start training from score -0.017675\n",
      "[LightGBM] [Info] Number of positive: 6457, number of negative: 6443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002902 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500543 -> initscore=0.002171\n",
      "[LightGBM] [Info] Start training from score 0.002171\n",
      "[LightGBM] [Info] Number of positive: 6448, number of negative: 6452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002097 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499845 -> initscore=-0.000620\n",
      "[LightGBM] [Info] Start training from score -0.000620\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002029 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6450, number of negative: 6449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001972 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000155\n",
      "[LightGBM] [Info] Start training from score 0.000155\n",
      "[LightGBM] [Info] Number of positive: 6472, number of negative: 6427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002105 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501744 -> initscore=0.006977\n",
      "[LightGBM] [Info] Start training from score 0.006977\n",
      "[LightGBM] [Info] Number of positive: 6455, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002005 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500426 -> initscore=0.001706\n",
      "[LightGBM] [Info] Start training from score 0.001706\n",
      "[LightGBM] [Info] Number of positive: 6481, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002132 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502403 -> initscore=0.009612\n",
      "[LightGBM] [Info] Start training from score 0.009612\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002067 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002081 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6393, number of negative: 6507\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002114 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495581 -> initscore=-0.017675\n",
      "[LightGBM] [Info] Start training from score -0.017675\n",
      "[LightGBM] [Info] Number of positive: 6457, number of negative: 6443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002213 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500543 -> initscore=0.002171\n",
      "[LightGBM] [Info] Start training from score 0.002171\n",
      "[LightGBM] [Info] Number of positive: 6448, number of negative: 6452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002115 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499845 -> initscore=-0.000620\n",
      "[LightGBM] [Info] Start training from score -0.000620\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002068 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6450, number of negative: 6449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002061 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000155\n",
      "[LightGBM] [Info] Start training from score 0.000155\n",
      "[LightGBM] [Info] Number of positive: 6472, number of negative: 6427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003545 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501744 -> initscore=0.006977\n",
      "[LightGBM] [Info] Start training from score 0.006977\n",
      "[LightGBM] [Info] Number of positive: 6455, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004377 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500426 -> initscore=0.001706\n",
      "[LightGBM] [Info] Start training from score 0.001706\n",
      "[LightGBM] [Info] Number of positive: 6481, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003173 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502403 -> initscore=0.009612\n",
      "[LightGBM] [Info] Start training from score 0.009612\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002729 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002702 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6393, number of negative: 6507\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005918 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495581 -> initscore=-0.017675\n",
      "[LightGBM] [Info] Start training from score -0.017675\n",
      "[LightGBM] [Info] Number of positive: 6457, number of negative: 6443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002705 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500543 -> initscore=0.002171\n",
      "[LightGBM] [Info] Start training from score 0.002171\n",
      "[LightGBM] [Info] Number of positive: 6448, number of negative: 6452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003094 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499845 -> initscore=-0.000620\n",
      "[LightGBM] [Info] Start training from score -0.000620\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003108 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6450, number of negative: 6449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003494 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000155\n",
      "[LightGBM] [Info] Start training from score 0.000155\n",
      "[LightGBM] [Info] Number of positive: 6472, number of negative: 6427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002931 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501744 -> initscore=0.006977\n",
      "[LightGBM] [Info] Start training from score 0.006977\n",
      "[LightGBM] [Info] Number of positive: 6455, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002931 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500426 -> initscore=0.001706\n",
      "[LightGBM] [Info] Start training from score 0.001706\n",
      "[LightGBM] [Info] Number of positive: 6481, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002958 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502403 -> initscore=0.009612\n",
      "[LightGBM] [Info] Start training from score 0.009612\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003996 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002743 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6393, number of negative: 6507\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002782 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495581 -> initscore=-0.017675\n",
      "[LightGBM] [Info] Start training from score -0.017675\n",
      "[LightGBM] [Info] Number of positive: 6457, number of negative: 6443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002802 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500543 -> initscore=0.002171\n",
      "[LightGBM] [Info] Start training from score 0.002171\n",
      "[LightGBM] [Info] Number of positive: 6448, number of negative: 6452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002843 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499845 -> initscore=-0.000620\n",
      "[LightGBM] [Info] Start training from score -0.000620\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002666 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6450, number of negative: 6449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002595 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000155\n",
      "[LightGBM] [Info] Start training from score 0.000155\n",
      "[LightGBM] [Info] Number of positive: 6472, number of negative: 6427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002973 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501744 -> initscore=0.006977\n",
      "[LightGBM] [Info] Start training from score 0.006977\n",
      "[LightGBM] [Info] Number of positive: 6455, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003499 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500426 -> initscore=0.001706\n",
      "[LightGBM] [Info] Start training from score 0.001706\n",
      "[LightGBM] [Info] Number of positive: 6481, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002842 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502403 -> initscore=0.009612\n",
      "[LightGBM] [Info] Start training from score 0.009612\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003054 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002803 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6393, number of negative: 6507\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002699 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495581 -> initscore=-0.017675\n",
      "[LightGBM] [Info] Start training from score -0.017675\n",
      "[LightGBM] [Info] Number of positive: 6457, number of negative: 6443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004615 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500543 -> initscore=0.002171\n",
      "[LightGBM] [Info] Start training from score 0.002171\n",
      "[LightGBM] [Info] Number of positive: 6448, number of negative: 6452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002813 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499845 -> initscore=-0.000620\n",
      "[LightGBM] [Info] Start training from score -0.000620\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002910 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6450, number of negative: 6449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002681 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000155\n",
      "[LightGBM] [Info] Start training from score 0.000155\n",
      "[LightGBM] [Info] Number of positive: 6472, number of negative: 6427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002676 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501744 -> initscore=0.006977\n",
      "[LightGBM] [Info] Start training from score 0.006977\n",
      "[LightGBM] [Info] Number of positive: 6455, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002790 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500426 -> initscore=0.001706\n",
      "[LightGBM] [Info] Start training from score 0.001706\n",
      "[LightGBM] [Info] Number of positive: 6481, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003418 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502403 -> initscore=0.009612\n",
      "[LightGBM] [Info] Start training from score 0.009612\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003646 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008813 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6393, number of negative: 6507\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002800 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495581 -> initscore=-0.017675\n",
      "[LightGBM] [Info] Start training from score -0.017675\n",
      "[LightGBM] [Info] Number of positive: 6457, number of negative: 6443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002819 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500543 -> initscore=0.002171\n",
      "[LightGBM] [Info] Start training from score 0.002171\n",
      "[LightGBM] [Info] Number of positive: 6448, number of negative: 6452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002909 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499845 -> initscore=-0.000620\n",
      "[LightGBM] [Info] Start training from score -0.000620\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002705 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6450, number of negative: 6449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002644 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000155\n",
      "[LightGBM] [Info] Start training from score 0.000155\n",
      "[LightGBM] [Info] Number of positive: 6472, number of negative: 6427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002731 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501744 -> initscore=0.006977\n",
      "[LightGBM] [Info] Start training from score 0.006977\n",
      "[LightGBM] [Info] Number of positive: 6455, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002852 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500426 -> initscore=0.001706\n",
      "[LightGBM] [Info] Start training from score 0.001706\n",
      "[LightGBM] [Info] Number of positive: 6481, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003076 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502403 -> initscore=0.009612\n",
      "[LightGBM] [Info] Start training from score 0.009612\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003850 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002641 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6393, number of negative: 6507\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003417 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495581 -> initscore=-0.017675\n",
      "[LightGBM] [Info] Start training from score -0.017675\n",
      "[LightGBM] [Info] Number of positive: 6457, number of negative: 6443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003207 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500543 -> initscore=0.002171\n",
      "[LightGBM] [Info] Start training from score 0.002171\n",
      "[LightGBM] [Info] Number of positive: 6448, number of negative: 6452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003057 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499845 -> initscore=-0.000620\n",
      "[LightGBM] [Info] Start training from score -0.000620\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003043 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6450, number of negative: 6449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002700 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000155\n",
      "[LightGBM] [Info] Start training from score 0.000155\n",
      "[LightGBM] [Info] Number of positive: 6472, number of negative: 6427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002671 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501744 -> initscore=0.006977\n",
      "[LightGBM] [Info] Start training from score 0.006977\n",
      "[LightGBM] [Info] Number of positive: 6455, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002652 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500426 -> initscore=0.001706\n",
      "[LightGBM] [Info] Start training from score 0.001706\n",
      "[LightGBM] [Info] Number of positive: 6481, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003168 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502403 -> initscore=0.009612\n",
      "[LightGBM] [Info] Start training from score 0.009612\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002686 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002671 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6393, number of negative: 6507\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002763 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495581 -> initscore=-0.017675\n",
      "[LightGBM] [Info] Start training from score -0.017675\n",
      "[LightGBM] [Info] Number of positive: 6457, number of negative: 6443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003966 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500543 -> initscore=0.002171\n",
      "[LightGBM] [Info] Start training from score 0.002171\n",
      "[LightGBM] [Info] Number of positive: 6448, number of negative: 6452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002814 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499845 -> initscore=-0.000620\n",
      "[LightGBM] [Info] Start training from score -0.000620\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002899 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6450, number of negative: 6449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002895 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000155\n",
      "[LightGBM] [Info] Start training from score 0.000155\n",
      "[LightGBM] [Info] Number of positive: 6472, number of negative: 6427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002767 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501744 -> initscore=0.006977\n",
      "[LightGBM] [Info] Start training from score 0.006977\n",
      "[LightGBM] [Info] Number of positive: 6455, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002740 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500426 -> initscore=0.001706\n",
      "[LightGBM] [Info] Start training from score 0.001706\n",
      "[LightGBM] [Info] Number of positive: 6481, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002766 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502403 -> initscore=0.009612\n",
      "[LightGBM] [Info] Start training from score 0.009612\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002826 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033840 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6393, number of negative: 6507\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002650 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495581 -> initscore=-0.017675\n",
      "[LightGBM] [Info] Start training from score -0.017675\n",
      "[LightGBM] [Info] Number of positive: 6457, number of negative: 6443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002933 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500543 -> initscore=0.002171\n",
      "[LightGBM] [Info] Start training from score 0.002171\n",
      "[LightGBM] [Info] Number of positive: 6448, number of negative: 6452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003266 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499845 -> initscore=-0.000620\n",
      "[LightGBM] [Info] Start training from score -0.000620\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003018 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6450, number of negative: 6449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003192 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000155\n",
      "[LightGBM] [Info] Start training from score 0.000155\n",
      "[LightGBM] [Info] Number of positive: 6472, number of negative: 6427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002719 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501744 -> initscore=0.006977\n",
      "[LightGBM] [Info] Start training from score 0.006977\n",
      "[LightGBM] [Info] Number of positive: 6455, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002836 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500426 -> initscore=0.001706\n",
      "[LightGBM] [Info] Start training from score 0.001706\n",
      "[LightGBM] [Info] Number of positive: 6481, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002930 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502403 -> initscore=0.009612\n",
      "[LightGBM] [Info] Start training from score 0.009612\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003502 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002717 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6393, number of negative: 6507\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002667 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495581 -> initscore=-0.017675\n",
      "[LightGBM] [Info] Start training from score -0.017675\n",
      "[LightGBM] [Info] Number of positive: 6457, number of negative: 6443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003196 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500543 -> initscore=0.002171\n",
      "[LightGBM] [Info] Start training from score 0.002171\n",
      "[LightGBM] [Info] Number of positive: 6448, number of negative: 6452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002697 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499845 -> initscore=-0.000620\n",
      "[LightGBM] [Info] Start training from score -0.000620\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002693 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6450, number of negative: 6449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002806 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000155\n",
      "[LightGBM] [Info] Start training from score 0.000155\n",
      "[LightGBM] [Info] Number of positive: 6472, number of negative: 6427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002576 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501744 -> initscore=0.006977\n",
      "[LightGBM] [Info] Start training from score 0.006977\n",
      "[LightGBM] [Info] Number of positive: 6455, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002765 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500426 -> initscore=0.001706\n",
      "[LightGBM] [Info] Start training from score 0.001706\n",
      "[LightGBM] [Info] Number of positive: 6481, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003225 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502403 -> initscore=0.009612\n",
      "[LightGBM] [Info] Start training from score 0.009612\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003680 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002808 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6393, number of negative: 6507\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002885 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495581 -> initscore=-0.017675\n",
      "[LightGBM] [Info] Start training from score -0.017675\n",
      "[LightGBM] [Info] Number of positive: 6457, number of negative: 6443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003027 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500543 -> initscore=0.002171\n",
      "[LightGBM] [Info] Start training from score 0.002171\n",
      "[LightGBM] [Info] Number of positive: 6448, number of negative: 6452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003531 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499845 -> initscore=-0.000620\n",
      "[LightGBM] [Info] Start training from score -0.000620\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002907 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6450, number of negative: 6449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002788 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000155\n",
      "[LightGBM] [Info] Start training from score 0.000155\n",
      "[LightGBM] [Info] Number of positive: 6472, number of negative: 6427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002981 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501744 -> initscore=0.006977\n",
      "[LightGBM] [Info] Start training from score 0.006977\n",
      "[LightGBM] [Info] Number of positive: 6455, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002900 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500426 -> initscore=0.001706\n",
      "[LightGBM] [Info] Start training from score 0.001706\n",
      "[LightGBM] [Info] Number of positive: 6481, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003287 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502403 -> initscore=0.009612\n",
      "[LightGBM] [Info] Start training from score 0.009612\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002960 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002660 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6393, number of negative: 6507\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006630 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495581 -> initscore=-0.017675\n",
      "[LightGBM] [Info] Start training from score -0.017675\n",
      "[LightGBM] [Info] Number of positive: 6457, number of negative: 6443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002989 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500543 -> initscore=0.002171\n",
      "[LightGBM] [Info] Start training from score 0.002171\n",
      "[LightGBM] [Info] Number of positive: 6448, number of negative: 6452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003139 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499845 -> initscore=-0.000620\n",
      "[LightGBM] [Info] Start training from score -0.000620\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002699 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6450, number of negative: 6449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002518 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000155\n",
      "[LightGBM] [Info] Start training from score 0.000155\n",
      "[LightGBM] [Info] Number of positive: 6472, number of negative: 6427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002740 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501744 -> initscore=0.006977\n",
      "[LightGBM] [Info] Start training from score 0.006977\n",
      "[LightGBM] [Info] Number of positive: 6455, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002817 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500426 -> initscore=0.001706\n",
      "[LightGBM] [Info] Start training from score 0.001706\n",
      "[LightGBM] [Info] Number of positive: 6481, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002993 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502403 -> initscore=0.009612\n",
      "[LightGBM] [Info] Start training from score 0.009612\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003235 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002862 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6393, number of negative: 6507\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002703 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495581 -> initscore=-0.017675\n",
      "[LightGBM] [Info] Start training from score -0.017675\n",
      "[LightGBM] [Info] Number of positive: 6457, number of negative: 6443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003092 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500543 -> initscore=0.002171\n",
      "[LightGBM] [Info] Start training from score 0.002171\n",
      "[LightGBM] [Info] Number of positive: 6448, number of negative: 6452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499845 -> initscore=-0.000620\n",
      "[LightGBM] [Info] Start training from score -0.000620\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002681 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6450, number of negative: 6449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002688 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000155\n",
      "[LightGBM] [Info] Start training from score 0.000155\n",
      "[LightGBM] [Info] Number of positive: 6472, number of negative: 6427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003076 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501744 -> initscore=0.006977\n",
      "[LightGBM] [Info] Start training from score 0.006977\n",
      "[LightGBM] [Info] Number of positive: 6455, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002668 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500426 -> initscore=0.001706\n",
      "[LightGBM] [Info] Start training from score 0.001706\n",
      "[LightGBM] [Info] Number of positive: 6481, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025749 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502403 -> initscore=0.009612\n",
      "[LightGBM] [Info] Start training from score 0.009612\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003595 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003034 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6393, number of negative: 6507\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004060 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495581 -> initscore=-0.017675\n",
      "[LightGBM] [Info] Start training from score -0.017675\n",
      "[LightGBM] [Info] Number of positive: 6457, number of negative: 6443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003005 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500543 -> initscore=0.002171\n",
      "[LightGBM] [Info] Start training from score 0.002171\n",
      "[LightGBM] [Info] Number of positive: 6448, number of negative: 6452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003443 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499845 -> initscore=-0.000620\n",
      "[LightGBM] [Info] Start training from score -0.000620\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002896 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6450, number of negative: 6449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003420 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000155\n",
      "[LightGBM] [Info] Start training from score 0.000155\n",
      "[LightGBM] [Info] Number of positive: 6472, number of negative: 6427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003509 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501744 -> initscore=0.006977\n",
      "[LightGBM] [Info] Start training from score 0.006977\n",
      "[LightGBM] [Info] Number of positive: 6455, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002753 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500426 -> initscore=0.001706\n",
      "[LightGBM] [Info] Start training from score 0.001706\n",
      "[LightGBM] [Info] Number of positive: 6481, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002809 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502403 -> initscore=0.009612\n",
      "[LightGBM] [Info] Start training from score 0.009612\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002784 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003648 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6393, number of negative: 6507\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002817 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495581 -> initscore=-0.017675\n",
      "[LightGBM] [Info] Start training from score -0.017675\n",
      "[LightGBM] [Info] Number of positive: 6457, number of negative: 6443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003422 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500543 -> initscore=0.002171\n",
      "[LightGBM] [Info] Start training from score 0.002171\n",
      "[LightGBM] [Info] Number of positive: 6448, number of negative: 6452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002917 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499845 -> initscore=-0.000620\n",
      "[LightGBM] [Info] Start training from score -0.000620\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002920 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6450, number of negative: 6449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002753 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000155\n",
      "[LightGBM] [Info] Start training from score 0.000155\n",
      "[LightGBM] [Info] Number of positive: 6472, number of negative: 6427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003458 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501744 -> initscore=0.006977\n",
      "[LightGBM] [Info] Start training from score 0.006977\n",
      "[LightGBM] [Info] Number of positive: 6455, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002771 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500426 -> initscore=0.001706\n",
      "[LightGBM] [Info] Start training from score 0.001706\n",
      "[LightGBM] [Info] Number of positive: 6481, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003149 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502403 -> initscore=0.009612\n",
      "[LightGBM] [Info] Start training from score 0.009612\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002751 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002758 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6393, number of negative: 6507\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002640 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495581 -> initscore=-0.017675\n",
      "[LightGBM] [Info] Start training from score -0.017675\n",
      "[LightGBM] [Info] Number of positive: 6457, number of negative: 6443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002963 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500543 -> initscore=0.002171\n",
      "[LightGBM] [Info] Start training from score 0.002171\n",
      "[LightGBM] [Info] Number of positive: 6448, number of negative: 6452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003420 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499845 -> initscore=-0.000620\n",
      "[LightGBM] [Info] Start training from score -0.000620\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002930 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6450, number of negative: 6449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003271 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000155\n",
      "[LightGBM] [Info] Start training from score 0.000155\n",
      "[LightGBM] [Info] Number of positive: 6472, number of negative: 6427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002779 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501744 -> initscore=0.006977\n",
      "[LightGBM] [Info] Start training from score 0.006977\n",
      "[LightGBM] [Info] Number of positive: 6455, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002572 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500426 -> initscore=0.001706\n",
      "[LightGBM] [Info] Start training from score 0.001706\n",
      "[LightGBM] [Info] Number of positive: 6481, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002861 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502403 -> initscore=0.009612\n",
      "[LightGBM] [Info] Start training from score 0.009612\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002928 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002713 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6393, number of negative: 6507\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003618 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495581 -> initscore=-0.017675\n",
      "[LightGBM] [Info] Start training from score -0.017675\n",
      "[LightGBM] [Info] Number of positive: 6457, number of negative: 6443\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006989 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500543 -> initscore=0.002171\n",
      "[LightGBM] [Info] Start training from score 0.002171\n",
      "[LightGBM] [Info] Number of positive: 6448, number of negative: 6452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002763 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499845 -> initscore=-0.000620\n",
      "[LightGBM] [Info] Start training from score -0.000620\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002619 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6450, number of negative: 6449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003491 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000155\n",
      "[LightGBM] [Info] Start training from score 0.000155\n",
      "[LightGBM] [Info] Number of positive: 6472, number of negative: 6427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002862 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501744 -> initscore=0.006977\n",
      "[LightGBM] [Info] Start training from score 0.006977\n",
      "[LightGBM] [Info] Number of positive: 6455, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002893 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500426 -> initscore=0.001706\n",
      "[LightGBM] [Info] Start training from score 0.001706\n",
      "[LightGBM] [Info] Number of positive: 6481, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003586 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502403 -> initscore=0.009612\n",
      "[LightGBM] [Info] Start training from score 0.009612\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003150 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002838 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6393, number of negative: 6507\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002873 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495581 -> initscore=-0.017675\n",
      "[LightGBM] [Info] Start training from score -0.017675\n",
      "[LightGBM] [Info] Number of positive: 6457, number of negative: 6443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002906 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500543 -> initscore=0.002171\n",
      "[LightGBM] [Info] Start training from score 0.002171\n",
      "[LightGBM] [Info] Number of positive: 6448, number of negative: 6452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002743 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499845 -> initscore=-0.000620\n",
      "[LightGBM] [Info] Start training from score -0.000620\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002699 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6450, number of negative: 6449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002982 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000155\n",
      "[LightGBM] [Info] Start training from score 0.000155\n",
      "[LightGBM] [Info] Number of positive: 6472, number of negative: 6427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501744 -> initscore=0.006977\n",
      "[LightGBM] [Info] Start training from score 0.006977\n",
      "[LightGBM] [Info] Number of positive: 6455, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002714 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500426 -> initscore=0.001706\n",
      "[LightGBM] [Info] Start training from score 0.001706\n",
      "[LightGBM] [Info] Number of positive: 6481, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002750 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502403 -> initscore=0.009612\n",
      "[LightGBM] [Info] Start training from score 0.009612\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002973 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002627 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6393, number of negative: 6507\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003067 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495581 -> initscore=-0.017675\n",
      "[LightGBM] [Info] Start training from score -0.017675\n",
      "[LightGBM] [Info] Number of positive: 6457, number of negative: 6443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003178 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500543 -> initscore=0.002171\n",
      "[LightGBM] [Info] Start training from score 0.002171\n",
      "[LightGBM] [Info] Number of positive: 6448, number of negative: 6452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003007 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499845 -> initscore=-0.000620\n",
      "[LightGBM] [Info] Start training from score -0.000620\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002689 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6450, number of negative: 6449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002741 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000155\n",
      "[LightGBM] [Info] Start training from score 0.000155\n",
      "[LightGBM] [Info] Number of positive: 6472, number of negative: 6427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002584 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501744 -> initscore=0.006977\n",
      "[LightGBM] [Info] Start training from score 0.006977\n",
      "[LightGBM] [Info] Number of positive: 6455, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002682 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500426 -> initscore=0.001706\n",
      "[LightGBM] [Info] Start training from score 0.001706\n",
      "[LightGBM] [Info] Number of positive: 6481, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002930 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502403 -> initscore=0.009612\n",
      "[LightGBM] [Info] Start training from score 0.009612\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002725 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006724 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6393, number of negative: 6507\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002829 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495581 -> initscore=-0.017675\n",
      "[LightGBM] [Info] Start training from score -0.017675\n",
      "[LightGBM] [Info] Number of positive: 6457, number of negative: 6443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002847 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500543 -> initscore=0.002171\n",
      "[LightGBM] [Info] Start training from score 0.002171\n",
      "[LightGBM] [Info] Number of positive: 6448, number of negative: 6452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002673 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499845 -> initscore=-0.000620\n",
      "[LightGBM] [Info] Start training from score -0.000620\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002701 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6450, number of negative: 6449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003248 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000155\n",
      "[LightGBM] [Info] Start training from score 0.000155\n",
      "[LightGBM] [Info] Number of positive: 6472, number of negative: 6427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003477 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501744 -> initscore=0.006977\n",
      "[LightGBM] [Info] Start training from score 0.006977\n",
      "[LightGBM] [Info] Number of positive: 6455, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003400 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500426 -> initscore=0.001706\n",
      "[LightGBM] [Info] Start training from score 0.001706\n",
      "[LightGBM] [Info] Number of positive: 6481, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002817 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502403 -> initscore=0.009612\n",
      "[LightGBM] [Info] Start training from score 0.009612\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003559 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003316 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6393, number of negative: 6507\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002657 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495581 -> initscore=-0.017675\n",
      "[LightGBM] [Info] Start training from score -0.017675\n",
      "[LightGBM] [Info] Number of positive: 6457, number of negative: 6443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002760 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500543 -> initscore=0.002171\n",
      "[LightGBM] [Info] Start training from score 0.002171\n",
      "[LightGBM] [Info] Number of positive: 6448, number of negative: 6452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002857 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499845 -> initscore=-0.000620\n",
      "[LightGBM] [Info] Start training from score -0.000620\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003156 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6450, number of negative: 6449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002766 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000155\n",
      "[LightGBM] [Info] Start training from score 0.000155\n",
      "[LightGBM] [Info] Number of positive: 6472, number of negative: 6427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002931 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501744 -> initscore=0.006977\n",
      "[LightGBM] [Info] Start training from score 0.006977\n",
      "[LightGBM] [Info] Number of positive: 6455, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002726 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500426 -> initscore=0.001706\n",
      "[LightGBM] [Info] Start training from score 0.001706\n",
      "[LightGBM] [Info] Number of positive: 6481, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003168 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502403 -> initscore=0.009612\n",
      "[LightGBM] [Info] Start training from score 0.009612\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002722 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003727 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6393, number of negative: 6507\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002691 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495581 -> initscore=-0.017675\n",
      "[LightGBM] [Info] Start training from score -0.017675\n",
      "[LightGBM] [Info] Number of positive: 6457, number of negative: 6443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002813 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500543 -> initscore=0.002171\n",
      "[LightGBM] [Info] Start training from score 0.002171\n",
      "[LightGBM] [Info] Number of positive: 6448, number of negative: 6452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003512 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499845 -> initscore=-0.000620\n",
      "[LightGBM] [Info] Start training from score -0.000620\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003085 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6450, number of negative: 6449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002888 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000155\n",
      "[LightGBM] [Info] Start training from score 0.000155\n",
      "[LightGBM] [Info] Number of positive: 6472, number of negative: 6427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002664 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501744 -> initscore=0.006977\n",
      "[LightGBM] [Info] Start training from score 0.006977\n",
      "[LightGBM] [Info] Number of positive: 6455, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002678 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500426 -> initscore=0.001706\n",
      "[LightGBM] [Info] Start training from score 0.001706\n",
      "[LightGBM] [Info] Number of positive: 6481, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003561 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502403 -> initscore=0.009612\n",
      "[LightGBM] [Info] Start training from score 0.009612\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002823 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003128 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6393, number of negative: 6507\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002761 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495581 -> initscore=-0.017675\n",
      "[LightGBM] [Info] Start training from score -0.017675\n",
      "[LightGBM] [Info] Number of positive: 6457, number of negative: 6443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002970 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500543 -> initscore=0.002171\n",
      "[LightGBM] [Info] Start training from score 0.002171\n",
      "[LightGBM] [Info] Number of positive: 6448, number of negative: 6452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003045 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499845 -> initscore=-0.000620\n",
      "[LightGBM] [Info] Start training from score -0.000620\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002758 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6450, number of negative: 6449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003790 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000155\n",
      "[LightGBM] [Info] Start training from score 0.000155\n",
      "[LightGBM] [Info] Number of positive: 6472, number of negative: 6427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002699 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501744 -> initscore=0.006977\n",
      "[LightGBM] [Info] Start training from score 0.006977\n",
      "[LightGBM] [Info] Number of positive: 6455, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002715 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500426 -> initscore=0.001706\n",
      "[LightGBM] [Info] Start training from score 0.001706\n",
      "[LightGBM] [Info] Number of positive: 6481, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002853 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502403 -> initscore=0.009612\n",
      "[LightGBM] [Info] Start training from score 0.009612\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002902 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002699 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6393, number of negative: 6507\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002688 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495581 -> initscore=-0.017675\n",
      "[LightGBM] [Info] Start training from score -0.017675\n",
      "[LightGBM] [Info] Number of positive: 6457, number of negative: 6443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002832 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500543 -> initscore=0.002171\n",
      "[LightGBM] [Info] Start training from score 0.002171\n",
      "[LightGBM] [Info] Number of positive: 6448, number of negative: 6452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002758 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499845 -> initscore=-0.000620\n",
      "[LightGBM] [Info] Start training from score -0.000620\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005967 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6450, number of negative: 6449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006960 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000155\n",
      "[LightGBM] [Info] Start training from score 0.000155\n",
      "[LightGBM] [Info] Number of positive: 6472, number of negative: 6427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002668 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501744 -> initscore=0.006977\n",
      "[LightGBM] [Info] Start training from score 0.006977\n",
      "[LightGBM] [Info] Number of positive: 6455, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003810 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500426 -> initscore=0.001706\n",
      "[LightGBM] [Info] Start training from score 0.001706\n",
      "[LightGBM] [Info] Number of positive: 6481, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002672 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502403 -> initscore=0.009612\n",
      "[LightGBM] [Info] Start training from score 0.009612\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002706 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002874 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6393, number of negative: 6507\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002780 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495581 -> initscore=-0.017675\n",
      "[LightGBM] [Info] Start training from score -0.017675\n",
      "[LightGBM] [Info] Number of positive: 6457, number of negative: 6443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002987 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500543 -> initscore=0.002171\n",
      "[LightGBM] [Info] Start training from score 0.002171\n",
      "[LightGBM] [Info] Number of positive: 6448, number of negative: 6452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002898 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499845 -> initscore=-0.000620\n",
      "[LightGBM] [Info] Start training from score -0.000620\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003004 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6450, number of negative: 6449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002732 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000155\n",
      "[LightGBM] [Info] Start training from score 0.000155\n",
      "[LightGBM] [Info] Number of positive: 6472, number of negative: 6427\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002635 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501744 -> initscore=0.006977\n",
      "[LightGBM] [Info] Start training from score 0.006977\n",
      "[LightGBM] [Info] Number of positive: 6455, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002651 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500426 -> initscore=0.001706\n",
      "[LightGBM] [Info] Start training from score 0.001706\n",
      "[LightGBM] [Info] Number of positive: 6481, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002890 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502403 -> initscore=0.009612\n",
      "[LightGBM] [Info] Start training from score 0.009612\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002851 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002654 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6393, number of negative: 6507\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002723 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495581 -> initscore=-0.017675\n",
      "[LightGBM] [Info] Start training from score -0.017675\n",
      "[LightGBM] [Info] Number of positive: 6457, number of negative: 6443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003164 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500543 -> initscore=0.002171\n",
      "[LightGBM] [Info] Start training from score 0.002171\n",
      "[LightGBM] [Info] Number of positive: 6448, number of negative: 6452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003938 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499845 -> initscore=-0.000620\n",
      "[LightGBM] [Info] Start training from score -0.000620\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002817 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 7170, number of negative: 7163\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003228 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 14333, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500244 -> initscore=0.000977\n",
      "[LightGBM] [Info] Start training from score 0.000977\n",
      "Best parameters: {'learning_rate': 0.1, 'n_estimators': 500, 'num_leaves': 51}\n",
      "[LightGBM] [Info] Number of positive: 6450, number of negative: 6449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002634 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000155\n",
      "[LightGBM] [Info] Start training from score 0.000155\n",
      "[LightGBM] [Info] Number of positive: 6472, number of negative: 6427\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006110 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501744 -> initscore=0.006977\n",
      "[LightGBM] [Info] Start training from score 0.006977\n",
      "[LightGBM] [Info] Number of positive: 6455, number of negative: 6444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002621 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12899, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500426 -> initscore=0.001706\n",
      "[LightGBM] [Info] Start training from score 0.001706\n",
      "[LightGBM] [Info] Number of positive: 6481, number of negative: 6419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003027 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502403 -> initscore=0.009612\n",
      "[LightGBM] [Info] Start training from score 0.009612\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002462 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002645 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "[LightGBM] [Info] Number of positive: 6393, number of negative: 6507\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002534 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495581 -> initscore=-0.017675\n",
      "[LightGBM] [Info] Start training from score -0.017675\n",
      "[LightGBM] [Info] Number of positive: 6457, number of negative: 6443\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002528 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500543 -> initscore=0.002171\n",
      "[LightGBM] [Info] Start training from score 0.002171\n",
      "[LightGBM] [Info] Number of positive: 6448, number of negative: 6452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003037 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499845 -> initscore=-0.000620\n",
      "[LightGBM] [Info] Start training from score -0.000620\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6442\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002924 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 12900, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500620 -> initscore=0.002481\n",
      "[LightGBM] [Info] Start training from score 0.002481\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92      7163\n",
      "           1       0.92      0.91      0.92      7170\n",
      "\n",
      "    accuracy                           0.92     14333\n",
      "   macro avg       0.92      0.92      0.92     14333\n",
      "weighted avg       0.92      0.92      0.92     14333\n",
      "\n",
      "[[6590  573]\n",
      " [ 619 6551]]\n",
      "Average Accuracy: 0.916835275238959\n",
      "Average Precision: 0.9168513837552084\n",
      "Average Recall: 0.9168368228096071\n",
      "Average F1 Score: 0.9168346594989378\n",
      "Average ROC AUC: 1.0\n",
      "Average Specificity: 0.9200055842524082\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n",
    "\n",
    "# 参数网格\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'num_leaves': [31, 41, 51]\n",
    "}\n",
    "\n",
    "# 创建 LightGBM 分类器\n",
    "gbm = LGBMClassifier()\n",
    "\n",
    "# 创建 KFold 交叉验证分割器\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# 创建网格搜索对象，使用 KFold 交叉验证\n",
    "grid_search = GridSearchCV(estimator=gbm, param_grid=param_grid, cv=kf, scoring='accuracy', verbose=1)\n",
    "\n",
    "# 执行网格搜索\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 最佳参数和最佳模型\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# 使用最佳模型进行交叉验证预测\n",
    "y_pred = cross_val_predict(best_model, X_train, y_train, cv=kf)\n",
    "\n",
    "# 计算所有指标的平均值\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "precision = precision_score(y_train, y_pred, average='macro')\n",
    "recall = recall_score(y_train, y_pred, average='macro')\n",
    "f1 = f1_score(y_train, y_pred, average='macro')\n",
    "\n",
    "# 如果是二分类问题，计算ROC AUC\n",
    "if len(set(y_train)) == 2:\n",
    "    y_scores = best_model.predict_proba(X_train)[:, 1]\n",
    "    roc_auc = roc_auc_score(y_train, y_scores)\n",
    "else:\n",
    "    roc_auc = None  # 对于多分类问题，ROC AUC需要不同的处理\n",
    "\n",
    "# 打印分类报告\n",
    "print(classification_report(y_train, y_pred))\n",
    "\n",
    "# 打印混淆矩阵\n",
    "conf_mat = confusion_matrix(y_train, y_pred)\n",
    "print(conf_mat)\n",
    "\n",
    "# 输出每个指标的平均值\n",
    "print(\"Average Accuracy:\", accuracy)\n",
    "print(\"Average Precision:\", precision)\n",
    "print(\"Average Recall:\", recall)\n",
    "print(\"Average F1 Score:\", f1)\n",
    "if roc_auc is not None:\n",
    "    print(\"Average ROC AUC:\", roc_auc)\n",
    "\n",
    "# 计算Specificity\n",
    "tn, fp, fn, tp = conf_mat.ravel()\n",
    "specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "print(\"Average Specificity:\", specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee112a72-a8c4-4083-b005-ccbc79c8f6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Feature  Importance\n",
      "16            BMI        1556\n",
      "8             age         640\n",
      "6   family_income         594\n",
      "9             edu         531\n",
      "87        Stress1         521\n",
      "..            ...         ...\n",
      "69     HLS-SF12-8         118\n",
      "57     EQ-5D-5L-1          95\n",
      "3        chaiqian          79\n",
      "58     EQ-5D-5L-2          55\n",
      "59     EQ-5D-5L-3          29\n",
      "\n",
      "[96 rows x 2 columns]\n",
      "          Feature  Importance\n",
      "16            BMI        1556\n",
      "8             age         640\n",
      "6   family_income         594\n",
      "9             edu         531\n",
      "87        Stress1         521\n",
      "89        Stress3         459\n",
      "4     home_mianji         422\n",
      "19         BFI3_R         410\n",
      "82       Fitness2         409\n",
      "81       Fitness1         403\n"
     ]
    }
   ],
   "source": [
    "# 获取特征重要性\n",
    "feature_importances = best_model.feature_importances_\n",
    "\n",
    "# 排序特征\n",
    "feature_names = X.columns\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# 打印特征重要性排序\n",
    "print(importance_df)\n",
    "print(importance_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b0209bb-8934-408b-afd3-89ef8fe60aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_gbm_itemdep.joblib']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "dump(best_model, 'best_gbm_itemdep.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1abc4cb5-ca3e-49e8-b6f2-4b4c371a7f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "best_rf = load('best_rf_itemdep.joblib')\n",
    "best_gbm = load('best_gbm_itemdep.joblib')\n",
    "\n",
    "# 已经训练好随机森林模型\n",
    "feature_importances_rf = best_rf.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "# 将特征重要性和特征名组合成DataFrame\n",
    "importance_df_rf = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances_rf})\n",
    "\n",
    "feature_importances_lgbm = best_gbm.feature_importances_\n",
    "\n",
    "# 将特征重要性和特征名组合成DataFrame\n",
    "importance_df_lgbm = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances_lgbm})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9605aada-0404-44d4-8bc9-645b8e16bdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找到随机森林模型特征重要性中的最大值\n",
    "max_importance_rf = importance_df_rf['Importance'].max()\n",
    "\n",
    "# 对随机森林模型的特征重要性进行标准化，使最大特征值为100\n",
    "importance_df_rf['Standardized Importance'] = importance_df_rf['Importance'] * (100 / max_importance_rf)\n",
    "\n",
    "# 找到LightGBM模型特征重要性中的最大值\n",
    "max_importance_lgbm = importance_df_lgbm['Importance'].max()\n",
    "\n",
    "# 对LightGBM模型的特征重要性进行标准化，使最大特征值为100\n",
    "importance_df_lgbm['Standardized Importance'] = importance_df_lgbm['Importance'] * (100 / max_importance_lgbm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f053aa27-320f-4cc1-83c7-50e538a0abaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按照特征名进行合并\n",
    "merged_importance_df = pd.merge(importance_df_rf, importance_df_lgbm, on='Feature')\n",
    "\n",
    "# 计算每个特征的重要性平均值\n",
    "merged_importance_df['Average Importance'] = (merged_importance_df['Standardized Importance_x'] + merged_importance_df['Standardized Importance_y']) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ffc9221-245b-40a2-ab05-04570c91c633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Feature  Importance_x  Standardized Importance_x  Importance_y  \\\n",
      "0           liveStrict      0.005518                  12.184329           145   \n",
      "1                hukou      0.005588                  12.338284           188   \n",
      "2              homeNum      0.007796                  17.214408           282   \n",
      "3             chaiqian      0.001723                   3.804687            79   \n",
      "4          home_mianji      0.009774                  21.581534           422   \n",
      "5               zhaiwu      0.004634                  10.231481           237   \n",
      "6        family_income      0.008984                  19.836092           594   \n",
      "7               gender      0.007151                  15.790393           223   \n",
      "8                  age      0.012847                  28.366712           640   \n",
      "9                  edu      0.008595                  18.977957           531   \n",
      "10            marriage      0.017855                  39.425546           209   \n",
      "11           child_Num      0.008964                  19.793532           204   \n",
      "12          brosis_Num      0.015231                  33.630609           349   \n",
      "13                ocup      0.009047                  19.975786           308   \n",
      "14               smoke      0.003650                   8.058697           211   \n",
      "15               drink      0.005360                  11.836080           295   \n",
      "16                 BMI      0.016069                  35.480829          1556   \n",
      "17              BFI1_R      0.008665                  19.132199           390   \n",
      "18                BFI2      0.007217                  15.934641           322   \n",
      "19              BFI3_R      0.021997                  48.570543           410   \n",
      "20              BFI4_R      0.007224                  15.950321           370   \n",
      "21              BFI5_R      0.007437                  16.421108           352   \n",
      "22                BFI6      0.007299                  16.117331           304   \n",
      "23              BFI7_R      0.018285                  40.373627           354   \n",
      "24                BFI8      0.007019                  15.497715           294   \n",
      "25                BFI9      0.005991                  13.228086           281   \n",
      "26               BFI10      0.005367                  11.850072           222   \n",
      "27               PSSS1      0.006459                  14.262188           255   \n",
      "28               PSSS2      0.006526                  14.410767           198   \n",
      "29               PSSS3      0.011087                  24.480905           225   \n",
      "30               PSSS4      0.010088                  22.274898           245   \n",
      "31               PSSS5      0.005822                  12.855243           178   \n",
      "32               PSSS6      0.005385                  11.890475           153   \n",
      "33               PSSS7      0.005867                  12.953792           216   \n",
      "34               PSSS8      0.007567                  16.707838           232   \n",
      "35               PSSS9      0.005488                  12.118014           173   \n",
      "36              PSSS10      0.005571                  12.302093           151   \n",
      "37              PSSS11      0.006197                  13.682589           177   \n",
      "38              PSSS12      0.005532                  12.215237           172   \n",
      "39              NGSES1      0.007720                  17.045019           171   \n",
      "40              NGSES2      0.014930                  32.965328           141   \n",
      "41              NGSES3      0.006553                  14.469561           158   \n",
      "42              NGSES4      0.004837                  10.680405           160   \n",
      "43              NGSES5      0.006789                  14.991185           148   \n",
      "44              NGSES6      0.007793                  17.207027           134   \n",
      "45              NGSES7      0.005879                  12.980639           153   \n",
      "46              NGSES8      0.005181                  11.439189           139   \n",
      "47             FHS-SF1      0.017888                  39.496514           123   \n",
      "48             FHS-SF2      0.020373                  44.984779           185   \n",
      "49             FHS-SF3      0.020715                  45.740324           185   \n",
      "50             FHS-SF4      0.015761                  34.800179           154   \n",
      "51             FHS-SF5      0.014778                  32.629907           195   \n",
      "52           FHS-SF6_R      0.041375                  91.358957           302   \n",
      "53             FHS-SF7      0.010252                  22.636870           204   \n",
      "54             FHS-SF8      0.006433                  14.204124           186   \n",
      "55           FHS-SF9_R      0.029103                  64.260590           310   \n",
      "56          FHS-SF10_R      0.043995                  97.142777           333   \n",
      "57          EQ-5D-5L-1      0.005521                  12.189644            95   \n",
      "58          EQ-5D-5L-2      0.006195                  13.679356            55   \n",
      "59          EQ-5D-5L-3      0.004503                   9.942876            29   \n",
      "60          EQ-5D-5L-4      0.013812                  30.497340           198   \n",
      "61          EQ-5D-5L-5      0.045289                 100.000000           339   \n",
      "62          HLS-SF12-1      0.005124                  11.313614           143   \n",
      "63          HLS-SF12-2      0.007202                  15.903071           138   \n",
      "64          HLS-SF12-3      0.004634                  10.231919           182   \n",
      "65          HLS-SF12-4      0.005626                  12.422651           141   \n",
      "66          HLS-SF12-5      0.009089                  20.068569           163   \n",
      "67          HLS-SF12-6      0.006857                  15.141319           167   \n",
      "68          HLS-SF12-7      0.005370                  11.856515           134   \n",
      "69          HLS-SF12-8      0.006131                  13.537851           118   \n",
      "70          HLS-SF12-9      0.004608                  10.174748           123   \n",
      "71         HLS-SF12-10      0.005270                  11.635736           127   \n",
      "72         HLS-SF12-11      0.004849                  10.706597           156   \n",
      "73         HLS-SF12-12      0.006477                  14.302023           135   \n",
      "74             EBS-SF1      0.005902                  13.032218           218   \n",
      "75             EBS-SF2      0.006013                  13.277323           228   \n",
      "76             EBS-SF3      0.005067                  11.187219           192   \n",
      "77             EBS-SF4      0.005431                  11.991477           257   \n",
      "78             EBS-SF5      0.005605                  12.376603           218   \n",
      "79             EBS-SF6      0.005608                  12.383670           254   \n",
      "80             EBS-SF7      0.008298                  18.321982           298   \n",
      "81            Fitness1      0.009960                  21.991927           403   \n",
      "82            Fitness2      0.014831                  32.746500           409   \n",
      "83            Fitness3      0.027131                  59.906422           284   \n",
      "84            Fitness4      0.009305                  20.546308           316   \n",
      "85            Fitness5      0.019996                  44.152151           338   \n",
      "86            Fitness6      0.008211                  18.129994           327   \n",
      "87             Stress1      0.023203                  51.233914           521   \n",
      "88             Stress2      0.023362                  51.583948           383   \n",
      "89             Stress3      0.014438                  31.879766           459   \n",
      "90  Emontion_regulate1      0.011471                  25.328666           384   \n",
      "91  Emontion_regulate2      0.010631                  23.473935           328   \n",
      "92  Emontion_regulate3      0.008296                  18.318961           285   \n",
      "93  Emontion_regulate4      0.008258                  18.232946           301   \n",
      "94  Emontion_regulate5      0.007457                  16.465645           316   \n",
      "95  Emontion_regulate6      0.007740                  17.089884           310   \n",
      "\n",
      "    Standardized Importance_y  Average Importance  \n",
      "0                    9.318766           10.751547  \n",
      "1                   12.082262           12.210273  \n",
      "2                   18.123393           17.668900  \n",
      "3                    5.077121            4.440904  \n",
      "4                   27.120823           24.351178  \n",
      "5                   15.231362           12.731422  \n",
      "6                   38.174807           29.005450  \n",
      "7                   14.331620           15.061006  \n",
      "8                   41.131105           34.748909  \n",
      "9                   34.125964           26.551960  \n",
      "10                  13.431877           26.428711  \n",
      "11                  13.110540           16.452036  \n",
      "12                  22.429306           28.029958  \n",
      "13                  19.794344           19.885065  \n",
      "14                  13.560411           10.809554  \n",
      "15                  18.958869           15.397475  \n",
      "16                 100.000000           67.740414  \n",
      "17                  25.064267           22.098233  \n",
      "18                  20.694087           18.314364  \n",
      "19                  26.349614           37.460079  \n",
      "20                  23.778920           19.864621  \n",
      "21                  22.622108           19.521608  \n",
      "22                  19.537275           17.827303  \n",
      "23                  22.750643           31.562135  \n",
      "24                  18.894602           17.196158  \n",
      "25                  18.059126           15.643606  \n",
      "26                  14.267352           13.058712  \n",
      "27                  16.388175           15.325182  \n",
      "28                  12.724936           13.567851  \n",
      "29                  14.460154           19.470530  \n",
      "30                  15.745501           19.010200  \n",
      "31                  11.439589           12.147416  \n",
      "32                   9.832905           10.861690  \n",
      "33                  13.881748           13.417770  \n",
      "34                  14.910026           15.808932  \n",
      "35                  11.118252           11.618133  \n",
      "36                   9.704370           11.003232  \n",
      "37                  11.375321           12.528955  \n",
      "38                  11.053985           11.634611  \n",
      "39                  10.989717           14.017368  \n",
      "40                   9.061697           21.013512  \n",
      "41                  10.154242           12.311902  \n",
      "42                  10.282776           10.481591  \n",
      "43                   9.511568           12.251377  \n",
      "44                   8.611825           12.909426  \n",
      "45                   9.832905           11.406772  \n",
      "46                   8.933162           10.186175  \n",
      "47                   7.904884           23.700699  \n",
      "48                  11.889460           28.437119  \n",
      "49                  11.889460           28.814892  \n",
      "50                   9.897172           22.348676  \n",
      "51                  12.532134           22.581020  \n",
      "52                  19.408740           55.383849  \n",
      "53                  13.110540           17.873705  \n",
      "54                  11.953728           13.078926  \n",
      "55                  19.922879           42.091734  \n",
      "56                  21.401028           59.271903  \n",
      "57                   6.105398            9.147521  \n",
      "58                   3.534704            8.607030  \n",
      "59                   1.863753            5.903315  \n",
      "60                  12.724936           21.611138  \n",
      "61                  21.786632           60.893316  \n",
      "62                   9.190231           10.251923  \n",
      "63                   8.868895           12.385983  \n",
      "64                  11.696658           10.964289  \n",
      "65                   9.061697           10.742174  \n",
      "66                  10.475578           15.272074  \n",
      "67                  10.732648           12.936983  \n",
      "68                   8.611825           10.234170  \n",
      "69                   7.583548           10.560699  \n",
      "70                   7.904884            9.039816  \n",
      "71                   8.161954            9.898845  \n",
      "72                  10.025707           10.366152  \n",
      "73                   8.676093           11.489058  \n",
      "74                  14.010283           13.521251  \n",
      "75                  14.652956           13.965140  \n",
      "76                  12.339332           11.763276  \n",
      "77                  16.516710           14.254093  \n",
      "78                  14.010283           13.193443  \n",
      "79                  16.323907           14.353789  \n",
      "80                  19.151671           18.736826  \n",
      "81                  25.899743           23.945835  \n",
      "82                  26.285347           29.515924  \n",
      "83                  18.251928           39.079175  \n",
      "84                  20.308483           20.427395  \n",
      "85                  21.722365           32.937258  \n",
      "86                  21.015424           19.572709  \n",
      "87                  33.483290           42.358602  \n",
      "88                  24.614396           38.099172  \n",
      "89                  29.498715           30.689241  \n",
      "90                  24.678663           25.003665  \n",
      "91                  21.079692           22.276813  \n",
      "92                  18.316195           18.317578  \n",
      "93                  19.344473           18.788710  \n",
      "94                  20.308483           18.387064  \n",
      "95                  19.922879           18.506382  \n"
     ]
    }
   ],
   "source": [
    "print(merged_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3bd916f-81d3-4144-9ae3-e1cca893d7eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "# 使用模型1进行预测，获取预测概率\n",
    "y_pred_proba_model_rf = best_rf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# 使用模型2进行预测，获取预测概率\n",
    "y_pred_proba_model_gbm = best_gbm.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# 计算模型1的ROC曲线\n",
    "fpr_model1, tpr_model1, thresholds_model1 = roc_curve(y_val, y_pred_proba_model_rf)\n",
    "\n",
    "# 计算模型1的AUC值\n",
    "auc_model1 = auc(fpr_model1, tpr_model1)\n",
    "\n",
    "# 计算模型2的ROC曲线\n",
    "fpr_model2, tpr_model2, thresholds_model2 = roc_curve(y_val, y_pred_proba_model_gbm)\n",
    "\n",
    "# 计算模型2的AUC值\n",
    "auc_model2 = auc(fpr_model2, tpr_model2)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.title('ROC Curves of Multiple Models')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "# 绘制模型1的ROC曲线\n",
    "plt.plot(fpr_model1, tpr_model1, label='RT (AUC = {:.3f})'.format(auc_model1))\n",
    "\n",
    "# 绘制模型2的ROC曲线\n",
    "plt.plot(fpr_model2, tpr_model2, label='lGBM (AUC = {:.3f})'.format(auc_model2))\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61d7d462-7ec9-4322-841c-a27aab1dbe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加对角线\n",
    "#plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
    "# 修改标题\n",
    "# plt.title('Comparison of ROC Curves for Different Models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eccb0eba-e83c-439a-809e-5eb1dd8eb395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "feature_names = X.columns\n",
    "\n",
    "# 您想分析的特征名称\n",
    "feature_names_to_analyze = ['edu']\n",
    "\n",
    "# 使用字典来存储特征名称和它们对应的索引\n",
    "feature_index_map = {name: i for i, name in enumerate(feature_names)}\n",
    "\n",
    "# 将特征名称映射到索引\n",
    "features = [feature_index_map[name] for name in feature_names_to_analyze]\n",
    "\n",
    "# 绘制partial dependence图\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "PartialDependenceDisplay.from_estimator(best_rf, X, features, ax=ax, feature_names=feature_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c8c8e1c-a40e-47fd-8d9c-6491c453682c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "feature_names = X.columns\n",
    "\n",
    "# 您想分析的特征名称\n",
    "feature_names_to_analyze = ['age']\n",
    "\n",
    "# 使用字典来存储特征名称和它们对应的索引\n",
    "feature_index_map = {name: i for i, name in enumerate(feature_names)}\n",
    "\n",
    "# 将特征名称映射到索引\n",
    "features = [feature_index_map[name] for name in feature_names_to_analyze]\n",
    "\n",
    "# 绘制partial dependence图\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "PartialDependenceDisplay.from_estimator(best_rf, X, features, ax=ax, feature_names=feature_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "580771ac-1a80-476d-9fe1-1a62e5b143c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(merged_importance_df)\n",
    "df.to_excel(r'C:\\Users\\Lenovo\\Desktop\\ML_health\\merged_importance_df_itemdep.xlsx', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6321d8b2-0916-4ff6-bf69-412db6435294",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "''Python(MentalAssessment)''",
   "language": "python",
   "name": "mentalassessment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
